<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Bounded Rationality (Posts about universal approximator)</title><link>http://bjlkeng.github.io/</link><description></description><atom:link href="http://bjlkeng.github.io/categories/universal-approximator.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Sat, 23 Dec 2023 02:03:09 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Universal ResNet: The One-Neuron Approximator</title><link>http://bjlkeng.github.io/posts/universal-resnet-the-one-neuron-approximator/</link><dc:creator>Brian Keng</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;em&gt;"In theory, theory and practice are the same. In practice, they are not."&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I read a very interesting paper titled &lt;em&gt;ResNet with one-neuron hidden layers is
a Universal Approximator&lt;/em&gt; by Lin and Jegelka [1].
The paper describes a simplified Residual Network as a universal approximator,
giving some theoretical backing to the wildly successful ResNet architecture.
In this post, I'm going to talk about this paper and a few of the related
universal approximation theorems for neural networks.
Instead of going through all the theoretical stuff, I'm simply going introduce
some theorems and play around with some toy datasets to see if we can get close
to the theoretical limits.&lt;/p&gt;
&lt;p&gt;(You might also want to checkout my previous post where I played around with
ResNets: &lt;a class="reference external" href="http://bjlkeng.github.io/posts/residual-networks/"&gt;Residual Networks&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;&lt;a href="http://bjlkeng.github.io/posts/universal-resnet-the-one-neuron-approximator/"&gt;Read moreâ€¦&lt;/a&gt; (11 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>hidden layers</category><category>mathjax</category><category>neural networks</category><category>residual networks</category><category>ResNet</category><category>universal approximator</category><guid>http://bjlkeng.github.io/posts/universal-resnet-the-one-neuron-approximator/</guid><pubDate>Fri, 03 Aug 2018 12:03:28 GMT</pubDate></item></channel></rss>