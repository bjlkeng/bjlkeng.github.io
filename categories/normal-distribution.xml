<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Bounded Rationality (Posts about normal distribution)</title><link>http://bjlkeng.github.io/</link><description></description><atom:link href="http://bjlkeng.github.io/categories/normal-distribution.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Tue, 24 Oct 2023 01:51:42 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Normal Approximation to the Posterior Distribution</title><link>http://bjlkeng.github.io/posts/normal-approximations-to-the-posterior-distribution/</link><dc:creator>Brian Keng</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In this post, I'm going to write about how the ever versatile normal distribution can be used to approximate a Bayesian posterior distribution.  Unlike some other normal approximations, this is &lt;em&gt;not&lt;/em&gt; a direct application of the central limit theorem.  The result has a straight forward proof using Laplace's Method whose main ideas I will attempt to present.  I'll also simulate a simple scenario to see how it works in practice.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://bjlkeng.github.io/posts/normal-approximations-to-the-posterior-distribution/"&gt;Read more…&lt;/a&gt; (14 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>Bayesian</category><category>normal distribution</category><category>posterior</category><category>prior</category><category>probability</category><category>sampling</category><guid>http://bjlkeng.github.io/posts/normal-approximations-to-the-posterior-distribution/</guid><pubDate>Sat, 02 Apr 2016 19:22:54 GMT</pubDate></item><item><title>Sampling from a Normal Distribution</title><link>http://bjlkeng.github.io/posts/sampling-from-a-normal-distribution/</link><dc:creator>Brian Keng</dc:creator><description>&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;One of the most common probability distributions is the normal (or Gaussian) distribution.  Many natural phenomena can be modeled using a normal distribution.  It's also of great importance due to its relation to the &lt;a href="https://en.wikipedia.org/wiki/Central_limit_theorem"&gt;Central Limit Theorem&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this post, we'll be reviewing the normal distribution and looking at how to draw samples from it using two methods.  The first method using the central limit theorem, and the second method using the &lt;a href="https://en.wikipedia.org/wiki/Box%E2%80%93Muller_transform"&gt;Box-Muller transform&lt;/a&gt;.  As usual, some brief coverage of the mathematics and code will be included to help drive intuition.
&lt;/p&gt;&lt;p&gt;&lt;a href="http://bjlkeng.github.io/posts/sampling-from-a-normal-distribution/"&gt;Read more…&lt;/a&gt; (13 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>normal distribution</category><category>probability</category><category>sampling</category><guid>http://bjlkeng.github.io/posts/sampling-from-a-normal-distribution/</guid><pubDate>Sun, 29 Nov 2015 02:57:02 GMT</pubDate></item></channel></rss>