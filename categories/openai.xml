<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Bounded Rationality (Posts about OpenAI)</title><link>http://bjlkeng.github.io/</link><description></description><atom:link href="http://bjlkeng.github.io/categories/openai.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Tue, 04 Jun 2024 00:49:18 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Iterative Summarization using LLMs</title><link>http://bjlkeng.github.io/posts/iterative-summarization-using-llms/</link><dc:creator>Brian Keng</dc:creator><description>&lt;div&gt;&lt;p&gt;After being busy for the first part of the year, I finally have a bit of time
to work on this blog.  After a lot of thinking about how to best fit it into my
schedule, I've decided to &lt;em&gt;attempt&lt;/em&gt; to write shorter posts.  Although I do get
a lot of satisfaction writing long posts, it's not practical because of the
time commitment.  Better to break it up into smaller parts to be able to
"ship" often rather than perfect each post.
This also allows me to experiment with smaller scoped topics, which hopefully
will keep more more motivated as well.  Speaking of which...&lt;/p&gt;
&lt;p&gt;This post is about answering a random thought I had the other day: what would
happen if I kept passing an LLM's output back to itself?  I ran a few
experiments of trying to get the LLM to iteratively summarize or rephrase a
piece of text and the results are...  pretty much what you would expect.  But
if you don't know what to expect, then read on and find out what happened!&lt;/p&gt;
&lt;p&gt;&lt;a href="http://bjlkeng.github.io/posts/iterative-summarization-using-llms/"&gt;Read more…&lt;/a&gt; (8 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>blog</category><category>fixed point</category><category>LLM</category><category>mathjax</category><category>OpenAI</category><category>summarization</category><guid>http://bjlkeng.github.io/posts/iterative-summarization-using-llms/</guid><pubDate>Tue, 04 Jun 2024 00:21:43 GMT</pubDate></item><item><title>LLM Fun: Building a Q&amp;A Bot of Myself</title><link>http://bjlkeng.github.io/posts/building-a-qa-bot-of-me-with-openai-and-cloudflare/</link><dc:creator>Brian Keng</dc:creator><description>&lt;div&gt;&lt;p&gt;Unless you've been living under a rock, you've probably heard of large language
models (LLM) such as ChatGPT or Bard.  I'm not one for riding a hype train but
I do think LLMs are here to stay and either are going to have an impact as big
as mobile as an interface (my current best guess) or perhaps something as big as
the Internet itself.  In either case, it behooves me to do a bit more
investigation into this popular trend &lt;a class="footnote-reference brackets" href="http://bjlkeng.github.io/posts/building-a-qa-bot-of-me-with-openai-and-cloudflare/#id2" id="id1"&gt;1&lt;/a&gt;.  At the same time, there are a bunch
of other developer technologies that I've been wondering about like serverless
computing, modern dev tools, and LLM-based code assistants, so I thought why not
kill multiple birds with one stone.&lt;/p&gt;
&lt;p&gt;This post is going to describe how I built a question and answering bot of myself using
LLMs as well as my experience using the relevant developer tools such as
&lt;a class="reference external" href="https://chat.openai.com"&gt;ChatGPT&lt;/a&gt;, &lt;a class="reference external" href="https://github.com/features/copilot"&gt;Github Copilot&lt;/a&gt;, &lt;a class="reference external" href="https://workers.cloudflare.com/"&gt;Cloudflare workers&lt;/a&gt;, and a couple of other related ones.
I start out with my motivation for doing this project, some brief background
on the technologies, a description of how I built everything including some
evaluation on LLM outputs, and finally some commentary.  This post is a lot
less heavy on the math as compared to my previous ones but it still has some
good stuff so read on!&lt;/p&gt;
&lt;p&gt;&lt;a href="http://bjlkeng.github.io/posts/building-a-qa-bot-of-me-with-openai-and-cloudflare/"&gt;Read more…&lt;/a&gt; (41 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>Cloudflare</category><category>GPT</category><category>Javascript</category><category>LangChain</category><category>large language models</category><category>LLM</category><category>mathjax</category><category>OpenAI</category><category>Q&amp;A</category><guid>http://bjlkeng.github.io/posts/building-a-qa-bot-of-me-with-openai-and-cloudflare/</guid><pubDate>Mon, 25 Sep 2023 00:56:42 GMT</pubDate></item></channel></rss>