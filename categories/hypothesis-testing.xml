<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Bounded Rationality (hypothesis testing)</title><link>http://satisficing.briankeng.com/</link><description></description><atom:link href="http://satisficing.briankeng.com/categories/hypothesis-testing.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Sun, 15 May 2016 01:45:02 GMT</lastBuildDate><generator>https://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>A Primer on Statistical Inference and Hypothesis Testing</title><link>http://satisficing.briankeng.com/posts/hypothesis-testing/</link><dc:creator>Brian Keng</dc:creator><description>&lt;div&gt;&lt;p&gt;This post is about some fundamental concepts in classical (or frequentist)
statistics: inference and hypothesis testing.  A while back, I came to the
realization that I didn't have a good intuition of these concepts (at least
not to my liking) beyond the mechanical nature of applying them.
What was missing was how they related to a probabilistic view of the subject.
This bothered me since having a good intuition about a subject is
probably the most useful (and fun!) part of learning a subject.  So this post
is a result of my re-education on these topics.  Enjoy!&lt;/p&gt;
&lt;p&gt;&lt;a href="http://satisficing.briankeng.com/posts/hypothesis-testing/"&gt;Read moreâ€¦&lt;/a&gt; (19 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>frequentist statistics</category><category>hypothesis testing</category><category>mathjax</category><category>models</category><category>p-values</category><category>statistical inference</category><guid>http://satisficing.briankeng.com/posts/hypothesis-testing/</guid><pubDate>Sat, 09 Jan 2016 16:22:26 GMT</pubDate></item></channel></rss>