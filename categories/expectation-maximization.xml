<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Bounded Rationality (Posts about expectation-maximization)</title><link>http://bjlkeng.github.io/</link><description></description><atom:link href="http://bjlkeng.github.io/categories/expectation-maximization.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Sun, 18 Sep 2022 02:08:35 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>The Expectation-Maximization Algorithm</title><link>http://bjlkeng.github.io/posts/the-expectation-maximization-algorithm/</link><dc:creator>Brian Keng</dc:creator><description>&lt;div&gt;&lt;p&gt;This post is going to talk about a widely used method to find the
maximum likelihood (MLE) or maximum a posteriori (MAP) estimate of parameters
in latent variable models called the Expectation-Maximization algorithm.  You
have probably heard about the most famous variant of this algorithm called the
k-means algorithm for clustering.
Even though it's so ubiquitous, whenever I've tried to understand &lt;em&gt;why&lt;/em&gt; this
algorithm works, I never quite got the intuition right.  Now that I've taken
the time to work through the math, I'm going to &lt;em&gt;attempt&lt;/em&gt; to explain the
algorithm hopefully with a bit more clarity.  We'll start by going back to the
basics with latent variable models and the likelihood functions, then moving on
to showing the math with a simple Gaussian mixture model &lt;a class="footnote-reference brackets" href="http://bjlkeng.github.io/posts/the-expectation-maximization-algorithm/#id5" id="id1"&gt;1&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://bjlkeng.github.io/posts/the-expectation-maximization-algorithm/"&gt;Read moreâ€¦&lt;/a&gt; (18 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>expectation-maximization</category><category>gaussian mixture models</category><category>latent variables</category><category>mathjax</category><guid>http://bjlkeng.github.io/posts/the-expectation-maximization-algorithm/</guid><pubDate>Fri, 07 Oct 2016 12:47:47 GMT</pubDate></item></channel></rss>