<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Understanding math, machine learning, and data to a satisfactory degree.">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Bounded Rationality | Bounded Rationality</title>
<link href="assets/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="assets/css/rst.css" rel="stylesheet" type="text/css">
<link href="assets/css/code.css" rel="stylesheet" type="text/css">
<link href="assets/css/colorbox.css" rel="stylesheet" type="text/css">
<link href="assets/css/theme.css" rel="stylesheet" type="text/css">
<link href="assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<link rel="alternate" type="application/rss+xml" title="RSS" href="rss.xml">
<link rel="canonical" href="http://bjlkeng.github.io/">
<link rel="next" href="index-1.html" type="text/html">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]--><link rel="prefetch" href="posts/universal-resnet-the-one-neuron-approximator/" type="text/html">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="http://bjlkeng.github.io/">

                <span class="h1" id="blog-title">Bounded Rationality</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<p class="lead">Understanding math, machine learning, and data to a satisfactory degree.</p>
<!--
                
                <li><a href="/archive.html">Archive</a>
                <li><a href="/categories/">Tags</a>
                <li><a href="/rss.xml">RSS feed</a>

                 
-->
            </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            <div class="col-lg-9">
                
                

<div class="postindex">
    <article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/universal-resnet-the-one-neuron-approximator/" class="u-url">Universal ResNet: The One-Neuron Approximator</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">
                Brian Keng
            </span></p>
            <p class="dateline"><a href="posts/universal-resnet-the-one-neuron-approximator/" rel="bookmark"><time class="published dt-published" datetime="2018-08-03T08:03:28-04:00" title="2018-08-03 08:03">2018-08-03 08:03</time></a></p>
        </div>
    </header><div class="p-summary entry-summary">
    <div>
<p><em>"In theory, theory and practice are the same. In practice, they are not."</em></p>
<p>I read a very interesting paper titled <em>ResNet with one-neuron hidden layers is
a Universal Approximator</em> by Lin and Jegelka [1].
The paper describes a simplified Residual Network as a universal approximator,
giving some theoretical backing to the wildly successful ResNet architecture.
In this post, I'm going to talk about this paper and a few of the related
universal approximation theorems for neural networks.
Instead of going through all the theoretical stuff, I'm simply going introduce
some theorems and play around with some toy datasets to see if we can get close
to the theoretical limits.</p>
<p>(You might also want to checkout my previous post where I played around with
ResNets: <a class="reference external" href="posts/residual-networks">Residual Networks</a>)</p>
<p class="more"><a href="posts/universal-resnet-the-one-neuron-approximator/">Read more…</a></p>
</div>
    </div>
    </article><article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/hyperbolic-geometry-and-poincare-embeddings/" class="u-url">Hyperbolic Geometry and Poincaré Embeddings</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">
                Brian Keng
            </span></p>
            <p class="dateline"><a href="posts/hyperbolic-geometry-and-poincare-embeddings/" rel="bookmark"><time class="published dt-published" datetime="2018-06-17T08:20:18-04:00" title="2018-06-17 08:20">2018-06-17 08:20</time></a></p>
        </div>
    </header><div class="p-summary entry-summary">
    <div>
<p>This post is finally going to get back to some ML related topics.
In fact, the original reason I took that whole math-y detour in the previous
posts was to more deeply understand this topic.  It turns out trying to
under tensor calculus and differential geometry (even to a basic level) takes a
while!  Who knew?  In any case, we're getting back to our regularly scheduled program.</p>
<p>In this post, I'm going to explain one of the applications of an abstract
area of mathematics called hyperbolic geometry.  The reason why this area is of
interest is because there has been a surge of research showing its
application in various fields, chief among them is a paper by Facebook
researchers [1] in which they discuss how to utilize a model of hyperbolic
geometry to represent hierarchical relationships.  I'll cover some of
the math weighting more towards intuition, show some of their results, and also
show some sample code from Gensim.  Don't worry, this time I'll try much harder
not going to go down the rabbit hole of trying to explain all the math (no
promises though).</p>
<p>(Note: If you're unfamiliar with tensors or manifolds, I suggest getting a quick
overview with my previous two posts:
<a class="reference external" href="posts/tensors-tensors-tensors">Tensors, Tensors, Tensors</a> and
<a class="reference external" href="posts/manifolds">Manifolds: A Gentle Introduction</a>)</p>
<p class="more"><a href="posts/hyperbolic-geometry-and-poincare-embeddings/">Read more…</a></p>
</div>
    </div>
    </article><article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/manifolds/" class="u-url">Manifolds: A Gentle Introduction</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">
                Brian Keng
            </span></p>
            <p class="dateline"><a href="posts/manifolds/" rel="bookmark"><time class="published dt-published" datetime="2018-04-17T06:24:57-05:00" title="2018-04-17 06:24">2018-04-17 06:24</time></a></p>
        </div>
    </header><div class="p-summary entry-summary">
    <div>
<p>Following up on the math-y stuff from my <a class="reference external" href="posts/tensors-tensors-tensors">last post</a>,
I'm going to be taking a look at another concept that pops up in ML: manifolds.
It is most well-known in ML for its use in the
<a class="reference external" href="https://www.quora.com/What-is-the-Manifold-Hypothesis-in-Deep-Learning">manifold hypothesis</a>.
Manifolds belong to the branches of mathematics of topology and differential
geometry.  I'll be focusing more on the study of manifolds from the latter
category, which fortunately is a bit less abstract, more well behaved, and more
intuitive than the former.  As usual, I'll go through some intuition,
definitions, and examples to help clarify the ideas without going into too much
depth or formalities.  I hope you mani-like it!</p>
<p class="more"><a href="posts/manifolds/">Read more…</a></p>
</div>
    </div>
    </article><article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/tensors-tensors-tensors/" class="u-url">Tensors, Tensors, Tensors</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">
                Brian Keng
            </span></p>
            <p class="dateline"><a href="posts/tensors-tensors-tensors/" rel="bookmark"><time class="published dt-published" datetime="2018-03-13T08:24:57-05:00" title="2018-03-13 08:24">2018-03-13 08:24</time></a></p>
        </div>
    </header><div class="p-summary entry-summary">
    <div>
<p>This post is going to take a step back from some of the machine learning
topics that I've been writing about recently and go back to some basics: math!
In particular, tensors.  This is a topic that is casually mentioned in machine
learning papers but for those of us who weren't physics or math majors
(*cough* computer engineers), it's a bit murky trying to understand what's going on.
So on my most recent vacation, I started reading a variety of sources on the
interweb trying to piece together a picture of what tensors were all
about.  As usual, I'll skip the heavy formalities (partly because I probably
couldn't do them justice) and instead try to explain the intuition using my
usual approach of examples and more basic maths.  I'll sprinkle in a bunch of
examples and also try to relate it back to ML where possible.  Hope you like
it!</p>
<p class="more"><a href="posts/tensors-tensors-tensors/">Read more…</a></p>
</div>
    </div>
    </article><article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/residual-networks/" class="u-url">Residual Networks</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">
                Brian Keng
            </span></p>
            <p class="dateline"><a href="posts/residual-networks/" rel="bookmark"><time class="published dt-published" datetime="2018-02-18T13:55:13-05:00" title="2018-02-18 13:55">2018-02-18 13:55</time></a></p>
        </div>
    </header><div class="p-summary entry-summary">
    <div>
<p>Taking a small break from some of the heavier math, I thought I'd write a post
(aka learn more about) a very popular neural network architecture called
Residual Networks aka ResNet.  This architecture is being very widely used
because it's so simple yet so powerful at the same time.  The architecture's
performance is due its ability to add hundreds of layers (talk about deep
learning!) without degrading performance or adding difficulty to training.  I
really like these types of robust advances where it doesn't require fiddling
with all sorts of hyper-parameters to make it work.  Anyways, I'll introduce
the idea and show an implementation of ResNet on a few runs of a variational
autoencoder that I put together on the CIFAR10 dataset.</p>
<p class="more"><a href="posts/residual-networks/">Read more…</a></p>
</div>
    </div>
    </article>
</div>

        <nav class="postindexpager"><ul class="pager">
<li class="next">
                <a href="index-1.html" rel="next">Older posts</a>
            </li>
        </ul></nav><script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script><script type="text/x-mathjax-config">
            MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']]}});
            </script>
</div>
            <div class="col-md-3 well">
            <p>
            I'm <a href="http://www.briankeng.com/about">Brian Keng</a>, 
            a former academic, current data scientist and engineer.  This is
            <a href=".">the place</a>
            where I write
            about all things technical.
            </p>
            <p>
            Twitter: <a href="http://www.twitter.com/bjlkeng">@bjlkeng</a>
            </p>

            <br><p>
            <a href="archive.html">Archive</a>
            </p>
            <p>
            <a href="categories/index.html">Tags</a>
            </p>
            <p>
            <a href="rss.xml">RSS feed</a>
            </p>

<!-- Begin MailChimp Signup Form -->
<hr>
<link href="//cdn-images.mailchimp.com/embedcode/classic-081711.css" rel="stylesheet" type="text/css">
<style type="text/css">
    #mc_embed_signup{clear:left; font:13px Helvetica,Arial,sans-serif; }
    /* Add your own MailChimp form style overrides in your site stylesheet or in this style block.
       We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
</style>
<div id="mc_embed_signup">
<form action="//briankeng.us10.list-manage.com/subscribe/post?u=cedf72ca8daa891e57f4379a0&amp;id=1f1563094f" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <b>Signup for Email Blog Posts</b>
    <div id="mc_embed_signup_scroll">
<div>
    <label for="mce-EMAIL"> Email Address </label>
    <input type="email" value="" name="EMAIL" class="required email form-control input-sm" id="mce-EMAIL">
</div>
    <div id="mce-responses" class="clear">
        <div class="response" id="mce-error-response" style="display:none"></div>
        <div class="response" id="mce-success-response" style="display:none"></div>
    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_cedf72ca8daa891e57f4379a0_1f1563094f" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="btn btn-default btn-xs"></div>
    </div>
</form>
</div>
<script type="text/javascript" src="//s3.amazonaws.com/downloads.mailchimp.com/js/mc-validate.js"></script><script type="text/javascript">(function($) {window.fnames = new Array(); window.ftypes = new Array();fnames[0]='EMAIL';ftypes[0]='email';fnames[1]='FNAME';ftypes[1]='text';fnames[2]='LNAME';ftypes[2]='text';}(jQuery));var $mcj = jQuery.noConflict(true);</script><!--End mc_embed_signup-->
</div>
        </div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2018         <a href="mailto:brian@briankeng.com">Brian Keng</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
        </footer>
</div>
</div>


            <script src="assets/js/jquery.min.js"></script><script src="assets/js/bootstrap.min.js"></script><script src="assets/js/moment-with-locales.min.js"></script><script src="assets/js/fancydates.js"></script><script src="assets/js/jquery.colorbox-min.js"></script><!-- <script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script> --><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-15314898-2', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>
