<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Understanding math, machine learning, and data to a satisfactory degree.">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Bounded Rationality (old posts, page 1) | Bounded Rationality</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="rss.xml">
<link rel="canonical" href="http://bjlkeng.github.io/index-1.html">
<link rel="prev" href="." type="text/html">
<link rel="next" href="index-2.html" type="text/html">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'left', // Change this to 'center' to center equations.
    displayIndent: '2em',
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": "0em 0em 1em 0em"}}
    }
});
</script><!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-md static-top mb-4
navbar-dark bg-dark
"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href="http://bjlkeng.github.io/">

            <span id="blog-title">Bounded Rationality</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav mr-auto">
<li class="nav-item">
<a href="archive.html" class="nav-link">Archive</a>
                </li>
<li class="nav-item">
<a href="categories/" class="nav-link">Tags</a>
                </li>
<li class="nav-item">
<a href="rss.xml" class="nav-link">RSS feed</a>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <div class="row">
        <!--Body content-->
            <div class="col-lg-9">
                
                
                

    


    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/an-introduction-to-stochastic-calculus/" class="u-url">An Introduction to Stochastic Calculus</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Brian Keng
            </span></p>
            <p class="dateline">
            <a href="posts/an-introduction-to-stochastic-calculus/" rel="bookmark">
            <time class="published dt-published" datetime="2022-09-11T21:05:55-04:00" itemprop="datePublished" title="2022-09-11 21:05">2022-09-11 21:05</time></a>
            </p>
        </div>
    </header><div class="p-summary entry-summary">
    <div>
<p>Through a couple of different avenues I wandered, yet again, down a rabbit hole
leading to the topic of this post.  The first avenue was through my main focus
on a particular machine learning topic that utilized some concepts from
physics, which naturally led me to stochastic calculus.  The second avenue was
through some projects at work in the quantitative finance space, which is one
of the main applications of stochastic calculus.  Naively, I thought I could
write a brief post on it that would satisfy my curiosity -- that didn't work
out at all! The result is this extra long post.</p>
<p>This post is about stochastic calculus, an extension of regular calculus to
stochastic processes.  It's not immediately obvious
but the rigour needed to properly understand some of the key ideas requires
going back to the measure theoretic definition of probability theory, so
that's where I start in the background. From there I quickly move on to
stochastic processes, the Wiener process, a particular flavour of stochastic
calculus called Itô calculus, and finally end with a couple of applications.
As usual, I try to include a mix of intuition, rigour where it helps intuition,
and some simple examples.  It's a deep and wide topic so I hope you enjoy my
digest of it.</p>
<p class="more"><a href="posts/an-introduction-to-stochastic-calculus/">Read more…</a></p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/normalizing-flows-with-real-nvp/" class="u-url">Normalizing Flows with Real NVP</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Brian Keng
            </span></p>
            <p class="dateline">
            <a href="posts/normalizing-flows-with-real-nvp/" rel="bookmark">
            <time class="published dt-published" datetime="2022-04-23T19:36:05-04:00" itemprop="datePublished" title="2022-04-23 19:36">2022-04-23 19:36</time></a>
            </p>
        </div>
    </header><div class="p-summary entry-summary">
    <div>
<p>This post has been a long time coming.  I originally started working on it several posts back but
hit a roadblock in the implementation and then got distracted with some other ideas, which took
me down various rabbit holes (<a class="reference external" href="posts/hamiltonian-monte-carlo/">here</a>,
<a class="reference external" href="posts/lossless-compression-with-asymmetric-numeral-systems/">here</a>, and
<a class="reference external" href="posts/lossless-compression-with-latent-variable-models-using-bits-back-coding/">here</a>).
It feels good to finally get back on track to some core ML topics.
The other nice thing about not being an academic researcher (not that I'm
really researching anything here) is that there is no pressure to do anything!
If it's just for fun, you can take your time with a topic, veer off track, and
the come back to it later.  It's nice having the freedom to do what you want (this applies to
more than just learning about ML too)!</p>
<p>This post is going to talk about a class of deep probabilistic generative
models called normalizing flows.  Alongside <a class="reference external" href="posts/variational-autoencoders/">Variational Autoencoders</a>
and autoregressive models <a class="footnote-reference brackets" href="posts/normalizing-flows-with-real-nvp/#id3" id="id1">1</a> (e.g. <a class="reference external" href="posts/pixelcnn/">Pixel CNN</a> and
<a class="reference external" href="posts/autoregressive-autoencoders/">Autoregressive autoencoders</a>),
normalizing flows have been one of the big ideas in deep probabilistic generative models (I don't count GANs because they are not quite probabilistic).
Specifically, I'll be presenting one of the earlier normalizing flow
techniques named <em>Real NVP</em> (circa 2016).
The formulation is simple but surprisingly effective, which makes it a good
candidate to understand more about normalizing flows.
As usual, I'll go over some background, the method, an implementation
(with commentary on the details), and some experimental results.  Let's get into the flow!</p>
<p class="more"><a href="posts/normalizing-flows-with-real-nvp/">Read more…</a></p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/hamiltonian-monte-carlo/" class="u-url">Hamiltonian Monte Carlo</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Brian Keng
            </span></p>
            <p class="dateline">
            <a href="posts/hamiltonian-monte-carlo/" rel="bookmark">
            <time class="published dt-published" datetime="2021-12-23T20:07:05-04:00" itemprop="datePublished" title="2021-12-23 20:07">2021-12-23 20:07</time></a>
            </p>
        </div>
    </header><div class="p-summary entry-summary">
    <div>
<p>Here's a topic I thought that I would never get around to learning because it was "too hard".
When I first started learning about Bayesian methods, I knew enough that I
should learn a thing or two about MCMC since that's the backbone
of most Bayesian analysis; so I learned something about it
(see my <a class="reference external" href="posts/markov-chain-monte-carlo-mcmc-and-the-metropolis-hastings-algorithm/">previous post</a>).
But I didn't dare attempt to learn about the infamous Hamiltonian Monte Carlo (HMC).
Even though it is among the standard algorithms used in Bayesian inference, it
always seemed too daunting because it required "advanced physics" to
understand.  As usual, things only seem hard because you don't know them yet.
After having some time to digest MCMC methods, getting comfortable learning
more maths (see
<a class="reference external" href="posts/tensors-tensors-tensors/">here</a>,
<a class="reference external" href="posts/manifolds/">here</a>, and
<a class="reference external" href="posts/hyperbolic-geometry-and-poincare-embeddings/">here</a>),
all of a sudden learning "advanced physics" didn't seem so tough (but there
sure was a lot of background needed)!</p>
<p>This post is the culmination of many different rabbit holes (many much deeper
than I needed to go) where I'm going to attempt to explain HMC in simple and
intuitive terms to a satisfactory degree (that's the tag line of this blog
after all).  I'm going to begin by briefly motivating the topic by reviewing
MCMC and the Metropolis-Hastings algorithm then move on to explaining
Hamiltonian dynamics (i.e., the "advanced physics"), and finally discuss the HMC
algorithm along with some toy experiments I put together.  Most of the material
is based on [1] and [2], which I've found to be great sources for their
respective areas.</p>
<p class="more"><a href="posts/hamiltonian-monte-carlo/">Read more…</a></p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/lossless-compression-with-latent-variable-models-using-bits-back-coding/" class="u-url">Lossless Compression with Latent Variable Models using Bits-Back Coding</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Brian Keng
            </span></p>
            <p class="dateline">
            <a href="posts/lossless-compression-with-latent-variable-models-using-bits-back-coding/" rel="bookmark">
            <time class="published dt-published" datetime="2021-07-06T11:00:00-05:00" itemprop="datePublished" title="2021-07-06 11:00">2021-07-06 11:00</time></a>
            </p>
        </div>
    </header><div class="p-summary entry-summary">
    <div>
<p>A lot of modern machine learning is related to this idea of "compression", or
maybe to use a fancier term "representations".  Taking a huge dimensional space
(e.g. images of 256 x 256 x 3 pixels = 196608 dimensions) and somehow compressing it into
a 1000 or so dimensional representation seems like pretty good compression to
me!  Unfortunately, it's not a lossless compression (or representation).
Somehow though, it seems intuitive that there must be a way to use what is learned in
these powerful lossy representations to help us better perform <em>lossless</em>
compression, right?  Of course there is! (It would be too anti-climatic of a
setup otherwise.)</p>
<p>This post is going to introduce a method to perform lossless compression that
leverages the learned "compression" of a machine learning latent variable
model using the Bits-Back coding algorithm.  Depending on how you first think
about it, this <em>seems</em> like it should either be (a) really easy or (b) not possible at
all.  The reality is kind of in between with an elegant theoretical algorithm
that is brought down by the realities of discretization and imperfect learning
by the model.  In today's post, I'll skim over some preliminaries (mostly
referring you to previous posts), go over the main Bits-Back coding algorithm
in detail, and discuss some of the implementation details and experiments that
I did while trying to write a toy version of the algorithm.</p>
<p class="more"><a href="posts/lossless-compression-with-latent-variable-models-using-bits-back-coding/">Read more…</a></p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/lossless-compression-with-asymmetric-numeral-systems/" class="u-url">Lossless Compression with Asymmetric Numeral Systems</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Brian Keng
            </span></p>
            <p class="dateline">
            <a href="posts/lossless-compression-with-asymmetric-numeral-systems/" rel="bookmark">
            <time class="published dt-published" datetime="2020-09-26T10:37:43-04:00" itemprop="datePublished" title="2020-09-26 10:37">2020-09-26 10:37</time></a>
            </p>
        </div>
    </header><div class="p-summary entry-summary">
    <div>
<p>During my undergraduate days, one of the most interesting courses I took was on
coding and compression.  Here was a course that combined algorithms,
probability and secret messages, what's not to like? <a class="footnote-reference brackets" href="posts/lossless-compression-with-asymmetric-numeral-systems/#id2" id="id1">1</a> I ended up not going
down that career path, at least partially because communications systems had
its heyday around the 2000s with companies like Nortel and Blackberry and its
predecessors (some like to joke that all the major theoretical breakthroughs
were done by Shannon and his discovery of information theory around 1950).  Fortunately, I
eventually wound up studying industrial applications of classical AI techniques
and then machine learning, which has really grown like crazy in the last 10
years or so.  Which is exactly why I was so surprised that a <em>new</em> and <em>better</em>
method of lossless compression was developed in 2009 <em>after</em> I finished my
undergraduate degree when I was well into my PhD.  It's a bit mind boggling that
something as well-studied as entropy-based lossless compression still had
(have?) totally new methods to discover, but I digress.</p>
<p>In this post, I'm going to write about a relatively new entropy based encoding
method called Asymmetrical Numeral Systems (ANS) developed by Jaroslaw (Jarek)
Duda [2].  If you've ever heard of Arithmetic Coding (probably best known for
its use in JPEG compression), ANS runs in a very similar vein.  It can
generate codes that are close to the theoretical compression limit
(similar to Arithmetic coding) but is <em>much</em> more efficient.  It's been used in
modern compression algorithms since 2014 including compressors developed
by Facebook, Apple and Google [3].  As usual, I'm going to go over some
background, some math, some examples to help with intuition, and finally some
experiments with a toy ANS implementation I wrote.  I hope you're as
excited as I am, let's begin!</p>
<p class="more"><a href="posts/lossless-compression-with-asymmetric-numeral-systems/">Read more…</a></p>
</div>
    </div>
    </article>
</div>

        <ul class="pager postindexpager clearfix">
<li class="previous"><a href="." rel="prev">Newer posts</a></li>
            <li class="next"><a href="index-2.html" rel="next">Older posts</a></li>
        </ul>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha384-3lJUsx1TJHt7BA4udB5KPnDrlkO8T6J6v/op7ui0BbCjvZ9WqV4Xm6DTP6kQ/iBH" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'left', // Change this to 'center' to center equations.
    displayIndent: '2em',
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": "0em 0em 1em 0em"}}
    }
});
</script>
</div>
            <div class="col-md-3 ">
            <div class="card card-body bg-light">
            <p>
            Hi, I'm <a href="http://www.briankeng.com/about">Brian Keng</a>.  This is
            <a href=".">the place</a> where I write about all things technical.
            </p>
            <p>
            Twitter: <a href="http://www.twitter.com/bjlkeng">@bjlkeng</a>
            </p>

            <br>
</div>

<!-- Begin MailChimp Signup Form -->
<hr>
<link href="//cdn-images.mailchimp.com/embedcode/classic-081711.css" rel="stylesheet" type="text/css">
<style type="text/css">
    #mc_embed_signup{clear:left; font:13px Helvetica,Arial,sans-serif; }
    /* Add your own MailChimp form style overrides in your site stylesheet or in this style block.
       We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
</style>
<div id="mc_embed_signup">
<form action="//briankeng.us10.list-manage.com/subscribe/post?u=cedf72ca8daa891e57f4379a0&amp;id=1f1563094f" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <b>Signup for Email Blog Posts</b>
    <div id="mc_embed_signup_scroll">
<div>
    <label for="mce-EMAIL"> Email Address </label>
    <input type="email" value="" name="EMAIL" class="required email form-control input-sm" id="mce-EMAIL">
</div>
    <div id="mce-responses" class="clear">
        <div class="response" id="mce-error-response" style="display:none"></div>
        <div class="response" id="mce-success-response" style="display:none"></div>
    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_cedf72ca8daa891e57f4379a0_1f1563094f" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="btn btn-default btn-xs"></div>
    </div>
</form>
</div>
<script type="text/javascript" src="//s3.amazonaws.com/downloads.mailchimp.com/js/mc-validate.js"></script><script type="text/javascript">(function($) {window.fnames = new Array(); window.ftypes = new Array();fnames[0]='EMAIL';ftypes[0]='email';fnames[1]='FNAME';ftypes[1]='text';fnames[2]='LNAME';ftypes[2]='text';}(jQuery));var $mcj = jQuery.noConflict(true);</script><!--End mc_embed_signup-->
</div>
            </div>
        </div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2024         <a href="mailto:brian@briankeng.com">Brian Keng</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
            
        </footer>
</div>



        <script src="assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-15314898-2', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>
