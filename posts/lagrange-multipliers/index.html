<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="A quick primer on lagrange multipliers.">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Lagrange Multipliers | Bounded Rationality</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.xml">
<link rel="canonical" href="http://bjlkeng.github.io/posts/lagrange-multipliers/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="description" itemprop="description" content="A quick primer on lagrange multipliers.">
<meta name="author" content="Brian Keng">
<link rel="prev" href="../the-expectation-maximization-algorithm/" title="The Expectation-Maximization Algorithm" type="text/html">
<link rel="next" href="../maximum-entropy-distributions/" title="Maximum Entropy Distributions" type="text/html">
<meta property="og:site_name" content="Bounded Rationality">
<meta property="og:title" content="Lagrange Multipliers">
<meta property="og:url" content="http://bjlkeng.github.io/posts/lagrange-multipliers/">
<meta property="og:description" content="A quick primer on lagrange multipliers.">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2016-12-13T07:48:31-05:00">
<meta property="article:tag" content="calculus">
<meta property="article:tag" content="lagrange multipliers">
<meta property="article:tag" content="mathjax">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="http://bjlkeng.github.io/">

                <span class="h1" id="blog-title">Bounded Rationality</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<p class="lead">Understanding data, math, and programming to a satisfactory degree.</p>
<!--
                
                <li><a href="/archive.html">Archive</a>
                <li><a href="/categories/">Tags</a>
                <li><a href="/rss.xml">RSS feed</a>

                 
-->
            </ul>
<ul class="nav navbar-nav navbar-right">
<li>
    <a href="index.rst" id="sourcelink">Source</a>
    </li>

                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            <div class="col-lg-9">
                
                
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Lagrange Multipliers</a></h1>

        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                    Brian Keng
            </span></p>
            <p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2016-12-13T07:48:31-05:00" itemprop="datePublished" title="2016-12-13 07:48">2016-12-13 07:48</time></a></p>
            
        <p class="sourceline"><a href="index.rst" id="sourcelink">Source</a></p>

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<p>This post is going to be about finding the maxima or minima of a function
subject to some constraints.  This is usually introduced in a multivariate
calculus course, unfortunately (or fortunately?) I never got the chance to take
a multivariate calculus course that covered this topic.  In my undergraduate class, computer
engineers only took three half year engineering calculus courses, and the
<a class="reference external" href="http://www.ucalendar.uwaterloo.ca/1617/COURSE/course-ECE.html#ECE206">fourth one</a>
(for electrical engineers) seems to have covered other basic multivariate
calculus topics such as all the various theorems such as Green's, Gauss', Stokes' (I
could be wrong though, I never did take that course!).  You know what I always imagined Newton
saying, "It's never too late to learn multivariate calculus!".</p>
<p>In that vein, this post will discuss one widely used method for finding optima
subject to constraints: Lagrange multipliers.  The concepts
behind it are actually quite intuitive once we come up with the right analogue
in physical reality, so as usual we'll start there.  We'll work through some
problems and hopefully by the end of this post, this topic won't seem as
mysterious anymore <a class="footnote-reference" href="#id3" id="id1">[1]</a>.</p>
<!-- TEASER_END -->
<p><br></p>
<h4> Motivation </h4>
<p>One of the most common problems of calculus is finding the minima or maxima of
a function.  We see this in a first year calculus course where we take the
derivative, set it to <span class="math">\(0\)</span>, and solve for <span class="math">\(x\)</span>.  Although this covers
a wide range of applications, there are <em>many</em> more interesting problems that
come up that don't fit into this simple mold.</p>
<p>A few interesting examples:</p>
<ol class="arabic simple">
<li>A simple (and uninteresting) question might be: "How do I minimize the
aluminum (surface area) I need to make this can?"  It's quite simple: just
make the can really, really small!  A more useful question might be: "How do
I minimize the aluminum (surface area) I need to make this can, assuming
that I need to hold <span class="math">\(250 cm^3\)</span> of liquid?"</li>
<li>
<a class="reference external" href="http://www.slimy.com/~steuard/teaching/tutorials/Lagrange.html">Milkmaid problem</a>:
Suppose we're a milkmaid (<span class="math">\(M\)</span>) in a large flat field trying to get to
our cow (<span class="math">\(C\)</span>) as fast as we can (so we can finish milking it and get
back to watching Westworld).  Before we can milk the cow, we have to clean
out our bucket in the river nearby (defined by <span class="math">\(g(x,y)=0\)</span>).  The
question becomes what is the best point on the river bank (<span class="math">\((x,y)\)</span>) to
minimize the total distance we need to get to the cow?  We want to minimize
distance here but clearly we also have the constraint that we must hit the
river bank first (otherwise we would just walk in a straight line).</li>
<li>Finding the maximum likelihood estimate (MLE) of a multinomial distribution
given some observations.  For example, suppose we have a weighted six-sided
die and we observe rolling it <span class="math">\(n\)</span> times (i.e. we have the count of the
number of times each side of the die has come up).  What is the MLE estimate
for each of the die probabilities (<span class="math">\(p_1, \ldots, p_6\)</span>)?  It's clear
we're maximizing the likelihood function but we're also subject to the constraint
that the probabilities need to sum to <span class="math">\(1\)</span>, i.e. <span class="math">\(\sum_{i=1}^6 p_i = 1\)</span>.</li>
</ol>
<p>We'll come back to these and try to solve them a bit later on.</p>
<p>The reason why these problems are more interesting is because many real-world
impose constraints on what we're trying to minimize/maximize (reality can be
pretty annoying sometimes!).  Fortunately, Lagrange multipliers can help us in
all three of these scenarios.</p>
<p><br></p>
<h4> Lagrange Multipliers </h4>
<p></p>
<h5> The Basics </h5>
<p>Let's start out with the simplest case in two dimensions since it's easier to
visualize.  We have a function <span class="math">\(f(x, y)\)</span> that we want to maximize and
also a constraint <span class="math">\(g(x, y)=0\)</span> that we must satisfy.  Translating this into a
physical situation, imagine <span class="math">\(f(x, y)\)</span> defines some hill.  At each
<span class="math">\((x,y)\)</span> location, we have the height of the hill.  Figure 1 shows
this as a blue (purple?) surface.  Now image we draw a red path (as shown in
Figure 1) on our <span class="math">\((x, y)\)</span> plane, defined by <span class="math">\(g(x, y)=0\)</span>.  We wish
to find the highest point on the hill that stays on this red path (i.e.
maximize <span class="math">\(f(x,y)\)</span> such that <span class="math">\(g(x,y)=0\)</span>).</p>
<div class="figure align-center">
<img alt="Lagrange Multipliers 3D (source: Wikipedia)" src="../../images/450px-LagrangeMultipliers3D.png" style="height: 300px;"><p class="caption">Figure 1: A 3D depiction of <span class="math">\(f(x,y)\)</span> (blue surface) and <span class="math">\(g(x,y)\)</span>
(red line). (source: Wikipedia)</p>
</div>
<p>If we imagine ourselves trying to solve this problem in the physical world, there is (at
least) one easy way to go about it: Keep walking along the red path, which
potentially will take you up and down the hill, until you find the highest
point (<span class="math">\(f(x,y)\)</span> maximized).  This brute force approach may be a simple way to
achieve our goal but remember that <span class="math">\(g(x,y)=0\)</span> might be infinitely long so
it's a bit less practical.  Instead, we'll do something a bit less exhaustive
and identify candidate points along the path that <em>may</em> end up being maxima
(i.e. necessary conditions).</p>
<p>Using our original idea of walking along the path, how do we know when we've
potentially come across a candidate maxima point?  Well, if we are walking uphill for a while
along the path and then suddenly start walking downhill.  If this sounds
familiar, this resembles the idea of setting derivative to <span class="math">\(0\)</span>.
In higher dimensions the generalization of the derivative is a gradient but
we're not simply setting it to <span class="math">\(0\)</span> because, remember, we're actually
walking along the <span class="math">\(g(x,y)\)</span> path.</p>
<div class="admonition admonition-gradients">
<p class="first admonition-title">Gradients</p>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Gradient">gradient</a>, denoted with the
<span class="math">\(\nabla\)</span> symbol, defines a vector of
the <span class="math">\(n\)</span> partial derivatives of a function of several variables:
<span class="math">\(\nabla f(x,y) = (\frac{\partial f(x,y)}{\partial x}, \frac{\partial
f(x,y)}{\partial y})\)</span>.  Similar to a single variable function, the direction
of the gradient points in the direction of the greatest rate of increase and its
magnitude is the slope in that direction.</p>
<p class="last">By this <a class="reference external" href="https://en.wikipedia.org/wiki/Level_set#Level_sets_versus_the_gradient">theorem</a>,
a <span class="math">\(\nabla f\)</span>'s direction is either zero or perpendicular to contours
(points at the same height)
of <span class="math">\(f\)</span>.  Using the analogy from Wikipedia, if you have two hikers at the same
place on our hill.  One hikes in the direction of steepest ascent uphill
(the gradient).  The other one is more timid and just walks along the hill
at the same height (contour lines).  The theorem says that the two hikers
will (initially) walk perpendicular to each other.</p>
</div>
<p>There are two cases to consider if we've walked up and down the hill while staying
along our path.  Either we've reached the top of the hill and the gradient of
<span class="math">\(f(x,y)\)</span> will be zero.  Or while walking along the path <span class="math">\(g(x,y)=0\)</span>,
we have reached a level part of <span class="math">\(f(x,y)\)</span> which means our <span class="math">\(f\)</span>
gradient is perpendicular to our path from the theorem in the box above.  But
since for this particular point, our path follows the level part of <span class="math">\(f\)</span>,
the gradient of <span class="math">\(g\)</span> at this point is also perpendicular to the path.
Hence, the two gradients are pointing in the same direction.  Figure 2 shows a
depiction of this idea in 2D, where blue is our hill, red is our path and the
arrows represent the gradient.</p>
<div class="figure align-center">
<img alt="Lagrange Multipliers 2D (source: Wikipedia)" src="../../images/450px-LagrangeMultipliers2D.png" style="height: 300px;"><p class="caption">Figure 2: A 2D depiction of <span class="math">\(f(x,y)\)</span> and <span class="math">\(g(x,y)=0\)</span>.  The
points on each ellipses define a constant height.  The arrows define the
direction of the gradient. (source: Wikipedia)</p>
</div>
<p>We can see that at our level point along the path, our red line is tangent to the
contour line of the hill, thus the gradients point in the same direction (up to
a constant multiplier).  This makes sense because our path and the contour line
follow the same direction (at least at that point), which means the gradients
(which are perpendicular to the path) must be equal.  Now there's no guarantee
that the magnitudes are the same, so we'll introduce a constant multiplier
called a <strong>Lagrange Multiplier</strong> to balance them.  Translating that into some
equations, we have:</p>
<div class="math">
\begin{align*}
\nabla f(x,y) &amp;= \lambda \nabla g(x, y) \tag{1} \\
g(x,y) &amp;= 0 \tag{2}
\end{align*}
</div>
<p>Equation 1 is what we just described, and Equation 2 is our original condition
on <span class="math">\(g(x,y)\)</span>.  That's it!  Lagrange multipliers are nothing more than
these equations. You have three equations (gradient in two dimensions has two
components) and three unknowns (<span class="math">\(x, y, \lambda\)</span>), so you can solve for
the values of <span class="math">\(x,y,\lambda\)</span> and find the point(s) that maximizes <span class="math">\(f\)</span>.
Note that this is a necessary, not sufficient condition.  Generally the solutions
will be <a class="reference external" href="https://en.wikipedia.org/wiki/Critical_point_(mathematics)">critical points</a> of <span class="math">\(f\)</span>, so
you probably will want to find all possible solutions and then pick the max/min
among those ones (or use another method to guarantee the global optima).</p>
<p></p>
<h5> The Lagrangian </h5>
<p>It turns out solving the solutions for Equation 1 and 2 are equivalent to
solving the maxima of another function called the  <em>Lagrangian</em>
<span class="math">\(\mathcal{L}\)</span>:</p>
<div class="math">
\begin{equation*}
\mathcal{L}(x, y, \lambda) = f(x,y) - \lambda g(x, y) \tag{3}
\end{equation*}
</div>
<p>If Equation 3 looks similar to the ones above, it should.  Using the usual method
of finding optima by taking the derivative and setting it to zero, we get:</p>
<div class="math">
\begin{align*}
\nabla_{x, y, \lambda} \mathcal{L}(x, y, \lambda) &amp;= 0 \\
\Longleftrightarrow \\
\frac{\partial f(x,y)}{\partial x} - \lambda \frac{\partial g(x,y)}{\partial x} &amp;= 0 \\
\frac{\partial f(x,y)}{\partial y} - \lambda \frac{\partial g(x,y)}{\partial y} &amp;= 0 \\
\frac{\partial f(x,y)}{\partial \lambda} - \frac{\lambda \partial g(x,y)}{\partial \lambda} &amp;= 0 \\
\Longleftrightarrow \\
\frac{\partial f(x,y)}{\partial x} = &amp;\lambda \frac{\partial g(x,y)}{\partial x} \\
\frac{\partial f(x,y)}{\partial y} = &amp;\lambda \frac{\partial g(x,y)}{\partial y} \\
g(x,y) = &amp;0
\tag{4}
\end{align*}
</div>
<p>As we can see, with a bit of manipulation these equations are equivalent to
Equations 1 and 2.  You'll probably see both ways of doing it depending on
which source you're using.</p>
<p></p>
<h5> Multiple Variables and Constraints </h5>
<p>Now the other non-trivial result is that Lagrange multipliers can extend to any
number of dimensions (<span class="math">\({\bf x} = (x_1, x_2, \ldots, x_n)\)</span>) and any number of
constraints (<span class="math">\(g_1({\bf x})=0, g_2({\bf x})=0, \ldots, g_m({\bf x}=0)\)</span>).
The setup for the Lagrangian is essentially the same thing with one Lagrange multiplier
for each constraint:</p>
<div class="math">
\begin{equation*}
\mathcal{L}(x_1, \ldots, x_n, \lambda_1, \ldots, \lambda_n) =
    f(x_1,\ldots, x_n) - \sum_{k=1}^{M} \lambda_k g_k(x_1, \ldots, x_n) \tag{5}
\end{equation*}
</div>
<p>This works out to solving <span class="math">\(n + M\)</span> equations with <span class="math">\(n + M\)</span> unknowns.</p>
<p><br></p>
<h4> Examples </h4>
<p>Now let's take a look at solving the examples from above to get a feel for how
Lagrange multipliers work.</p>
<div class="admonition admonition-example-1-minimizing-surface-area-of-a-can-given-a-constraint">
<p class="first admonition-title">Example 1: Minimizing surface area of a can given a constraint.</p>
<p><strong>Problem</strong>: Find the minimal surface area of a can with the constraint that its
volume needs to be at least <span class="math">\(250 cm^3\)</span>.</p>
<p>Recall the surface area of a cylinder is:</p>
<div class="math">
\begin{equation*}
A(r, h) = 2\pi rh + 2\pi r^2  \tag{6}
\end{equation*}
</div>
<p>This forms our "f" function.  Our constraint is pretty simple, the volume
needs to be at least <span class="math">\(K=250 cm^3\)</span>, using the formula for the volume
of a cylinder:</p>
<div class="math">
\begin{align*}
V(r, h) &amp;= \pi r^2 h = K \\
g(r, h) &amp;:= \pi r^2 h - K = 0 \tag{7}
\end{align*}
</div>
<p>Now using the method of Lagrange multipliers by taking the appropriate
derivative, we get the following equations:</p>
<div class="math">
\begin{align*}
\frac{\partial A(r, h)}{\partial r} &amp;= \lambda \frac{\partial V(r, h)}{\partial r} \\
2\pi h + 4\pi r &amp;= 2 \lambda \pi r h \\
2r + h(1-\lambda r) &amp;= 0 \tag{8}
\end{align*}
</div>
<div class="math">
\begin{align*}
\frac{\partial A(r, h)}{\partial h} &amp;= \lambda \frac{\partial V(r, h)}{\partial h} \\
2\pi r &amp;= \lambda \pi r^2  \\
r &amp;= \frac{2}{\lambda} \tag{9}
\end{align*}
</div>
<div class="math">
\begin{align*}
g(r, h) &amp;= \pi r^2 h - K = 0 \tag{10} \\
\end{align*}
</div>
<p>Solving 8, 9 and 10, we get:</p>
<div class="math">
\begin{align*}
\lambda &amp;= \sqrt[3]{\frac{16\pi}{K}} \\
r &amp;= 2\sqrt[3]{\frac{K}{16\pi}} \\
h &amp;= \frac{K}{4\pi}(\frac{16\pi}{K})^{\frac{2}{3}}
\tag{11}
\end{align*}
</div>
<p class="last">Plugging in K=250, we get (rounded) <span class="math">\(r=3.414, h=6.823\)</span>, giving a
volume of <span class="math">\(250 cm^3\)</span>, and a surface area of <span class="math">\(219.7 cm^2\)</span>.</p>
</div>
<div class="admonition admonition-example-2-milkmaid-problem">
<p class="first admonition-title">Example 2: Milkmaid Problem.</p>
<p>Since we don't have a concrete definition of <span class="math">\(g(x,y)\)</span>, we'll just
set this problem up.  The most important part is defining our function to
minimize.  Given our starting point <span class="math">\(P\)</span>, our point we hit along the
river <span class="math">\((x,y)\)</span>, and our cow <span class="math">\(C\)</span>, and also assuming a Euclidean
distance, we can come up with the total distance the milkmaid needs to walk:</p>
<div class="math">
\begin{equation*}
f(x,y) = \sqrt{(P_x - x)^2 + (P_y - y)^2} + \sqrt{(C_x - x)^2 + (C_y - y)^2}
\end{equation*}
</div>
<p class="last">From here, you can use the same method as above to solve for <span class="math">\(x\)</span> and
<span class="math">\(y\)</span> with the constraint for the river as <span class="math">\(g(x,y)=0\)</span>.</p>
</div>
<div class="admonition admonition-example-3-maximum-likelihood-estimate-mle-for-a-multinomial-distribution">
<p class="first admonition-title">Example 3: Maximum likelihood estimate (MLE) for a multinomial distribution.</p>
<p><strong>Problem</strong>: Suppose we have observed <span class="math">\(n\)</span> rolls of a six-sided die.
What is the MLE estimate for the probability of each side of the die
(<span class="math">\(p_1, \ldots, p_6\)</span>)?</p>
<p>Recall the log-likelihood of a <a class="reference external" href="https://en.wikipedia.org/wiki/Multinomial_distribution">multinomial distribution</a> with <span class="math">\(n\)</span> trials and observations <span class="math">\(x_1, \ldots, x_6\)</span>:</p>
<div class="math">
\begin{align*}
f(p_1, \ldots, p_6) &amp;= \log\mathcal{L}(p_1, \ldots, p_6) \\
&amp;= \log P(X_1 = x_1, \ldots, X_6 = x_6; p_1, \ldots, p_6) \\
&amp;= \log\big[ \frac{n!}{x_1! \ldots x_6!} p_1^{x_1} \ldots p_6^{x_6} \big] \\
&amp;= \log n! - \log x_1! - \ldots - \log x_6! + x_1 \log p_1 + \ldots x_6 \log p_6
\tag{12}
\end{align*}
</div>
<p>This defines our <span class="math">\(f\)</span> function to maximize with six variables
<span class="math">\(p_1, \ldots, p_6\)</span>.  Our constraint is that the probabilities must sum to 1:</p>
<div class="math">
\begin{equation*}
g(p_1, \ldots, p_6) = \sum_{k=1}^6 p_k - 1 = 0 \tag{13}
\end{equation*}
</div>
<p>Computing the partial derivatives:</p>
<div class="math">
\begin{align*}
\frac{\partial f(p_1, \ldots, p_6)}{\partial p_k} &amp;= \frac{x_k}{p_k} \tag{14} \\
\frac{\partial g(p_1, \ldots, p_6)}{\partial p_k} &amp;= 1 \tag{15}
\end{align*}
</div>
<p>Equations 13, 14, 15 gives us the following system of equations:</p>
<div class="math">
\begin{align*}
\frac{x_k}{p_k} &amp;= \lambda \text{ for } k=1,\ldots,6 \\
\sum_{k=1}^6 p_k - 1 &amp;= 0 \tag{16}
\end{align*}
</div>
<p>Solving the system of equations in 16 gives us:</p>
<div class="math">
\begin{align*}
\lambda &amp;= \sum_{k=1}^{6} x_k \\
p_k &amp;= \frac{x_k}{\lambda} = \frac{x_k}{\sum_{k=1}^{6} x_k} \tag{17}
\end{align*}
</div>
<p class="last">Which is exactly what you would expect from the MLE estimate: the
probability of a side coming up is proportional to the relative number of
times you have seen it come up.</p>
</div>
<p><br></p>
<h4> Conclusion </h4>
<p>Lagrange multipliers are one of those fundamental tools in calculus that some
of us never got around to learning.  This was really frustrating for me when
I was trying to work through some of the math that comes up in probability
texts such the problem above.  Like most things, it is much more mysterious
when you just have a passing reference to it in a textbook versus actually
taking the time to understand the intuition behind it.  I hope this tutorial
has helped some of you along with your understanding.</p>
<p><br></p>
<h4> Further Reading </h4>
<ul class="simple">
<li>Wikipedia: <a class="reference external" href="https://en.wikipedia.org/wiki/Lagrange_multiplier">Lagrange multiplier</a>,
<a class="reference external" href="https://en.wikipedia.org/wiki/Gradient">Gradient</a>
</li>
<li>
<a class="reference external" href="http://www.slimy.com/~steuard/teaching/tutorials/Lagrange.html">An Introduction to Lagrange Multipliers</a>, Steuard Jensen</li>
<li>
<a class="reference external" href="https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/constrained-optimization/a/lagrange-multipliers-single-constraint">Lagrange Multipliers</a>, Kahn Academy</li>
</ul>
<p><br></p>
<table class="docutils footnote" frame="void" id="id3" rules="none">
<colgroup>
<col class="label">
<col>
</colgroup>
<tbody valign="top"><tr>
<td class="label"><a class="fn-backref" href="#id1">[1]</a></td>
<td>This post draws heavily on a great tutorial by Steuard Jensen: <a class="reference external" href="http://www.slimy.com/~steuard/teaching/tutorials/Lagrange.html">An Introduction to Lagrange Multipliers</a>.  I highly encourage you to check it out.</td>
</tr></tbody>
</table>
</div>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/calculus/" rel="tag">calculus</a></li>
            <li><a class="tag p-category" href="../../categories/lagrange-multipliers/" rel="tag">lagrange multipliers</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../the-expectation-maximization-algorithm/" rel="prev" title="The Expectation-Maximization Algorithm">Previous post</a>
            </li>
            <li class="next">
                <a href="../maximum-entropy-distributions/" rel="next" title="Maximum Entropy Distributions">Next post</a>
            </li>
        </ul></nav></aside><script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script><script type="text/x-mathjax-config">
            MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']]}});
            </script></article>
</div>
            <div class="col-md-3 well">
            <p>
            I'm <a href="http://www.briankeng.com/about">Brian Keng</a>, 
            a former academic, current data scientist, engineer, and
            programmer.  This is
            <a href="../../">the place</a>
            where I write
            about all things technical.
            </p>
            <p>
            Twitter: <a href="http://www.twitter.com/bjlkeng">@bjlkeng</a>
            </p>

            <br><p>
            <a href="../../archive.html">Archive</a>
            </p>
            <p>
            <a href="../../categories/index.html">Tags</a>
            </p>
            <p>
            <a href="../../rss.xml">RSS feed</a>
            </p>

<!-- Begin MailChimp Signup Form -->
<hr>
<link href="//cdn-images.mailchimp.com/embedcode/classic-081711.css" rel="stylesheet" type="text/css">
<style type="text/css">
    #mc_embed_signup{clear:left; font:13px Helvetica,Arial,sans-serif; }
    /* Add your own MailChimp form style overrides in your site stylesheet or in this style block.
       We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
</style>
<div id="mc_embed_signup">
<form action="//briankeng.us10.list-manage.com/subscribe/post?u=cedf72ca8daa891e57f4379a0&amp;id=1f1563094f" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <b>Signup for Email Blog Posts</b>
    <div id="mc_embed_signup_scroll">
<div>
    <label for="mce-EMAIL"> Email Address </label>
    <input type="email" value="" name="EMAIL" class="required email form-control input-sm" id="mce-EMAIL">
</div>
    <div id="mce-responses" class="clear">
        <div class="response" id="mce-error-response" style="display:none"></div>
        <div class="response" id="mce-success-response" style="display:none"></div>
    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_cedf72ca8daa891e57f4379a0_1f1563094f" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="btn btn-default btn-xs"></div>
    </div>
</form>
</div>
<script type="text/javascript" src="//s3.amazonaws.com/downloads.mailchimp.com/js/mc-validate.js"></script><script type="text/javascript">(function($) {window.fnames = new Array(); window.ftypes = new Array();fnames[0]='EMAIL';ftypes[0]='email';fnames[1]='FNAME';ftypes[1]='text';fnames[2]='LNAME';ftypes[2]='text';}(jQuery));var $mcj = jQuery.noConflict(true);</script><!--End mc_embed_signup-->
</div>
        </div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2017         <a href="mailto:brian@briankeng.com">Brian Keng</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
        </footer>
</div>
</div>


            <script src="../../assets/js/all-nocdn.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-15314898-2', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>
