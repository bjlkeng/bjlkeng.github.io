<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content='A short post on the "Label Refinery" paper.'>
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Label Refinery: A Softer Approach | Bounded Rationality</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../../rss.xml">
<link rel="canonical" href="http://bjlkeng.github.io/posts/label-refinery/">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'left', // Change this to 'center' to center equations.
    displayIndent: '2em',
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": "0em 0em 1em 0em"}}
    }
});
</script><!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Brian Keng">
<link rel="prev" href="../universal-resnet-the-one-neuron-approximator/" title="Universal ResNet: The One-Neuron Approximator" type="text/html">
<link rel="next" href="../importance-sampling-and-estimating-marginal-likelihood-in-variational-autoencoders/" title="Importance Sampling and Estimating Marginal Likelihood in Variational Autoencoders" type="text/html">
<meta property="og:site_name" content="Bounded Rationality">
<meta property="og:title" content="Label Refinery: A Softer Approach">
<meta property="og:url" content="http://bjlkeng.github.io/posts/label-refinery/">
<meta property="og:description" content='A short post on the "Label Refinery" paper.'>
<meta property="og:type" content="article">
<meta property="article:published_time" content="2018-09-04T07:26:02-04:00">
<meta property="article:tag" content="CIFAR10">
<meta property="article:tag" content="label refinery">
<meta property="article:tag" content="mathjax">
<meta property="article:tag" content="residual networks">
<meta property="article:tag" content="svhn">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-md static-top mb-4
navbar-dark bg-dark
"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href="http://bjlkeng.github.io/">

            <span id="blog-title">Bounded Rationality</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav mr-auto">
<li class="nav-item">
<a href="../../archive.html" class="nav-link">Archive</a>
                </li>
<li class="nav-item">
<a href="../../categories/" class="nav-link">Tags</a>
                </li>
<li class="nav-item">
<a href="../../rss.xml" class="nav-link">RSS feed</a>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right">
<li class="nav-item">
    <a href="index.rst" id="sourcelink" class="nav-link">Source</a>
    </li>


                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <div class="row">
        <!--Body content-->
            <div class="col-lg-9">
                
                
                
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Label Refinery: A Softer Approach</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    Brian Keng
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2018-09-04T07:26:02-04:00" itemprop="datePublished" title="2018-09-04 07:26">2018-09-04 07:26</time></a>
            </p>
            
        <p class="sourceline"><a href="index.rst" class="sourcelink">Source</a></p>

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<p>This post is going to be about a really simple idea that is surprisingly effective
from a paper by Bagherinezhad et al. called <a class="reference external" href="https://arxiv.org/abs/1805.02641">Label Refinery: Improving ImageNet
Classification through Label Progression</a>.
The title pretty much says it all but I'll also discuss some intuition and show
some experiments on the CIFAR10 and SVHN datasets.  The idea is both simple and
surprising, my favourite kind of idea!  Let's take a look.</p>
<!-- TEASER_END -->
<p><em>Digression: This motivation in [1] is really good.  They have this great
spiel about how there is so much focus on improving the actual model and
relatively little work on the other parts, in particular, the labels!  What
brilliant a statement!  For any ML practitioner, they know that the most
important part is the data, the model is a distant second.  So why all the
focus on the models?  Well it's easier to publish I suppose and as a result
probably the most interesting academically.  Although I would guess some of the
most cited papers are probably benchmark papers, so that's something.
The people who are probably putting together really good datasets are probably
making money off of them and not publishing.  Go figure.</em></p>
<p><br></p>
<h4> Label Refinery </h4>
<p></p>
<h5> Main Idea </h5>
<p>Let's start off with the main idea because it's so simple.  All we're
going to do is train an image classification model, use its predicted outputs
<span class="math">\(y'\)</span> to train a <em>fresh</em> classification models using <span class="math">\(y'\)</span> in place
of the ground truth labels.  That's right: we're using the predicted labels
in place of ground truth labels!  The claim is that this "refinement" step
will improve your test accuracy.  Figure 1 from the paper shows this
visually.</p>
<div class="figure align-center">
<img alt="Label Refinery Illustration" src="../../images/label_refinery1.png" style="height: 200px;"><p class="caption">Figure 1: The basic idea behind Label Refinery (source: [1])</p>
</div>
<p>You can see at each iteration we're using the predicted labels ("Refined
Label") to feed into the next model as the training labels.  At some point, the last
model in the chain becomes your classifier.  Along the way, inexplicably, the
accuracy improves.</p>
<p>In more detail, for a given image classification problem:</p>
<ol class="arabic simple" start="0">
<li><p>Set <span class="math">\(y = y_{\text{truth}}\)</span> (ground truth labels).</p></li>
<li><p>Train a classifier <span class="math">\(R_1\)</span> with images <span class="math">\(X\)</span> and labels <span class="math">\(y\)</span>
from scratch.</p></li>
<li><p>Use <span class="math">\(R_1\)</span> to predict on <span class="math">\(X\)</span> to generate new "refined" labels,
call it <span class="math">\(y_{R_1}\)</span>; set <span class="math">\(y=y_{R_1}\)</span>.</p></li>
<li><p>Repeat steps 1-2 several times to iteratively generate new models
<span class="math">\(R_i\)</span> and "refined" labels <span class="math">\(y_{R_i}\)</span>.</p></li>
<li><p>At some point, use <span class="math">\(R_i\)</span> as your trained model.</p></li>
</ol>
<p>Huh? Why should this even work?  How can using a <em>less</em> accurate label (predicted
output) to train result in better accuracy?  It's actually quite simple.</p>
<p></p>
<h5> Intuition </h5>
<p>The big idea is that <em>images can have multiple labels</em>! Well... duh!  However,
this is a big problem for datasets like ImageNet where each image has exactly
one label (i.e. a <em>hard</em> label).  Take Figure 2 for example.</p>
<div class="figure align-center">
<img alt="Label Refinery Illustration" src="../../images/label_refinery2.png" style="height: 200px;"><p class="caption">Figure 2: Illustration of multiple label problem (source: [1])</p>
</div>
<p>Figure 2 shows a picture of a "Persian cat" from ImageNet's training set.  This
label is not bad but you could also conceivably label this image as a "ball" too.
This problem is magnified though when training a network using standard image augmentation
techniques such as cropping.  We can see the cropped image should clearly be
labelled as a "ball" and not "Persian cat".  However, if we add this augmented cropped
image to our dataset, it will just add noise making it harder for the
classifier to learn "Persian cat".  On the other hand, if we use the label refinery technique above,
we can have a <em>soft labelling</em> of the image.  So it could be "80% persian cat" and
"20% ball".  This help reduce overfitting to the training images.
The next figure shows another example of this.</p>
<div class="figure align-center">
<img alt="Label Refinery Illustration" src="../../images/label_refinery3.png" style="height: 200px;"><p class="caption">Figure 3: Examples of similar image patches. (source: [1])</p>
</div>
<p>Figure 3 shows examples of random crops of "dough" and "butternut squash".  You can
see that they are visually very similar.  Similarly, if we use hard labels for the
crops, we'll most likely have a very hard time learning the two
because for two similar images we have completely different labels.  Contrast
that with having a soft label of "dough", "butternut squash",
"burrito", "french loaf" etc. for the various patches.</p>
<div class="figure align-center">
<img alt="Label Refinery Illustration" src="../../images/label_refinery4.png" style="height: 400px;"><p class="caption">Figure 4: Examples of iterative refinement. (source: [1])</p>
</div>
<p>Figure 4 shows another example with the top three predictions at each iteration
of label refinery trained on AlexNet.  You can see that the first iteration
overfits to "barbershop" especially when considering the cropped "shop"
image.  Using label refinery on the fifth iteration, we have a more reasonable
soft labelling of "barbershop", "scoreboard", and "street sign" on the cropped image.
(Hopefully "barbershop" still is ranked high for the original image!)</p>
<p><br></p>
<h4> Experiments on CIFAR10 and SVHN </h4>
<p>The experiments in [1] were all about improving ImageNet classification across
its 1000 categories where the images were all relatively large in size (usually
pre-processed to 256x256).  I wondered how this idea would translate to other
datasets that could run on my meager GTX 1070.  To this end, I tried the label
refinery method on two much easier datasets: CIFAR10 [2] and SVHN [3].  The
former is a natural image dataset containing pictures of cars, animals,
etc., while the latter is a bunch of images of street view house numbers.</p>
<p>Testing our hypothesis that label refinery works well because of our soft labels,
we would expect that it might perform better on SVHN compared to CIFAR10 because
SVHN will actually have multiple labels in the same picture (multiple numbers in the
same image but only one hard label).  Figure 5 and 6 show samples from the
training data.</p>
<div class="figure align-center">
<img alt="CIFAR 10 Sample" src="../../images/label_refinery5.png" style="height: 300px;"><p class="caption">Figure 5: CIFAR10 Sample Images</p>
</div>
<div class="figure align-center">
<img alt="SVHN Sample" src="../../images/label_refinery6.png" style="height: 300px;"><p class="caption">Figure 6: SVHN Sample Images</p>
</div>
<p></p>
<h5> Experimental Setup </h5>
<p>I used the <a class="reference external" href="https://keras.io/applications/#resnet50">ResNet50</a> model from
Keras as my base classifier replacing the last layer with a 10-way softmax
dense layer (both datasets have 10 distinct labels).  I also augmented the
dataset with two times more images with random 10 degree rotations, 10% zoom
and 10% shifts in X or Y directions with an additional random horizontal flip
for CIFAR 10.  I used the <a class="reference external" href="https://keras.io/preprocessing/image/">ImageDataGenerator</a> class from Keras to make the
augmented images.  Usually for ImageNet you actually do a crop but since the
images are so small it doesn't quite make sense to do that.</p>
<p>Some other details from the implementation:</p>
<ul class="simple">
<li><p>The standard test set was used from both datasets</p></li>
<li><p>15% validation set from the training set</p></li>
<li><p>Categorical cross-entropy loss</p></li>
<li><p>Used Adam optimizer with reduced learning rate on loss plateau and early
stopping based on the validation set accuracy</p></li>
<li><p>Each combination below was run 5 times and the mean test accuracy and
standard deviation are reported</p></li>
</ul>
<p>All the code can be found <a class="reference external" href="https://github.com/bjlkeng/sandbox/tree/master/notebooks/label_refinery">here on Github</a>.</p>
<p></p>
<h5> Experimental Results </h5>
<p>Finally, let's take a look at the experiments!  Table 1 shows the results on
both datasets.</p>
<p><em>Table 1: Label Refinery Experiments with CIFAR10 and SVHN datasets with and without image augmentation.</em></p>
<table>
<colgroup>
<col style="width: 27%">
<col style="width: 18%">
<col style="width: 18%">
<col style="width: 18%">
<col style="width: 18%">
</colgroup>
<tbody>
<tr>
<td></td>
<td colspan="2"><p><strong>CIFAR10</strong></p></td>
<td colspan="2"><p><strong>SVHN</strong></p></td>
</tr>
<tr>
<td><p><strong>Label Refinery
Iteration</strong></p></td>
<td><p>Augment=0</p></td>
<td><p>Augment=1</p></td>
<td><p>Augment=0</p></td>
<td><p>Augment=1</p></td>
</tr>
<tr>
<td><p><span class="math">\(R_1\)</span></p></td>
<td><p>62.9 ± 6.7</p></td>
<td><p>68.7 ± 4.5</p></td>
<td><p>88.1 ± 2.7</p></td>
<td><p>91.0 ± 2.1</p></td>
</tr>
<tr>
<td><p><span class="math">\(R_2\)</span></p></td>
<td><p>44.2 ± 20</p></td>
<td><p>64.2 ± 11</p></td>
<td><p>73.1 ± 30</p></td>
<td><p>91.5 ± 1.3</p></td>
</tr>
<tr>
<td><p><span class="math">\(R_3\)</span></p></td>
<td><p>32.3 ± 22</p></td>
<td><p>59.0 ± 12</p></td>
<td><p>73.9 ± 31</p></td>
<td><p>91.5 ± 1.2</p></td>
</tr>
</tbody>
</table>
<p>From Table 1, the first column shows the label refinery iteration.  <span class="math">\(R_1\)</span> means
the first classifier in the refinery chain (using the ground truth labels),
<span class="math">\(R_2\)</span> means we took the output of <span class="math">\(R_1\)</span> and used it as labels for
training <span class="math">\(R_2\)</span> etc.  I also show results with and without the described
image augmentation.</p>
<p>The first thing to notice is that image augmentation
works pretty well!  The test set accuracy on the base classifiers go from 62.9%
to 68.7% and 88.1 to 91.0% on CIFAR10 and SVHN respectively.  That's pretty
good for just doing some simple transformations on images.  It makes sense
since the content of images are, for the most part, invariant to small
perturbations.  This basically just adds more varied training data, which of
course will make the classifier stronger.</p>
<p>The second thing to notice is that the label refinery technique performs poorly
on the CIFAR10 dataset.  I suspect that the main reason is the hypothesis we
stated above: the soft labels don't really help because there is no overlap in
labels in the pictures.  We can see that the performance varies so widely in
latter iterations.</p>
<p>Taking a look at SVHN, we see that without augmentation label refinery shows
similarly poor results.  However with augmentation, we do see some
marginal, relatively stable improvement from 91.0% to 91.5% mean test set
accuracy.  Although I should note that it only actually improved results on the
second iteration in 3 out of the 5 runs.  In the other two runs, it went from
92.5% to 91.5% to 91.9%, and 92.6% to 92.5% to 92.9%.  So still pretty good,
with only one run showing somewhat of a decrease.</p>
<p>Relating this back to the hypothesis above, here are some thoughts:</p>
<ol class="arabic simple">
<li><p>We actually have a use for the soft labels because some images indeed do
have multiple labels (more than one number in the image).</p></li>
<li><p>The augmentation might be needed with label refinery because the number of
images with multiple numbers is not very large, thus it is not able to make
use of multiple labels efficiently otherwise (the training algorithm might
just treat them as noise).</p></li>
<li><p>Along these lines, the classifier is able to learn more generalized digits
with the augmented images and soft labels.  For example, an image might be
labelled "3" but have numbers "123".  If we shift and zoom in on it, it might only
show "12".  The soft labels of course will help in this case, but it also
gives the classifier a chance to see additional examples of "1" and "2",
increasing its generalizing capability.</p></li>
</ol>
<p>The effect on SVHN is still relatively small though, most likely because
the label overlap problem is not as severe as ImageNet where they do actual
cropping.</p>
<p><br></p>
<h4> Conclusion </h4>
<p>Sometimes we focus too much on the super sexy models that do funky things like
GANs or Deep RL (or variational autoencoders!) and often don't pay much
attention to some of the simpler ideas.
I really like simple yet robust ideas like this label refinery because they
usually end up being more useful as well as more insightful.
It would be cool if label refinery could be applied to other types of domains like numeric
predictions but I don't think the effect would translate to non-images.
I'm working on another post but it might take a while to
get out because I'll be taking some vacation and will be super busy in the
fall.  Hopefully, I'll find some time in between to push it out before the end
of the year.  Thanks for reading!</p>
<p><br></p>
<h4> Further Reading </h4>
<ul class="simple">
<li><p>Previous posts: <a class="reference external" href="../residual-networks/">Residual Networks</a></p></li>
<li><p>My label refinery code: <a class="reference external" href="https://github.com/bjlkeng/sandbox/tree/master/notebooks/label_refinery">Github</a></p></li>
<li><p>[1] <a class="reference external" href="https://arxiv.org/abs/1805.02641">Label Refinery: Improving ImageNet Classification through Label Progression</a>, Hessam Bagherinezhad, Maxwell Horton, Mohammad Rastegari, Ali Farhadi</p></li>
<li><p>[2] <a class="reference external" href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10 Dataset</a></p></li>
<li><p>[3] <a class="reference external" href="http://ufldl.stanford.edu/housenumbers/">SVHN Dataset</a></p></li>
</ul>
</div>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/cifar10/" rel="tag">CIFAR10</a></li>
            <li><a class="tag p-category" href="../../categories/label-refinery/" rel="tag">label refinery</a></li>
            <li><a class="tag p-category" href="../../categories/residual-networks/" rel="tag">residual networks</a></li>
            <li><a class="tag p-category" href="../../categories/svhn/" rel="tag">svhn</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../universal-resnet-the-one-neuron-approximator/" rel="prev" title="Universal ResNet: The One-Neuron Approximator">Previous post</a>
            </li>
            <li class="next">
                <a href="../importance-sampling-and-estimating-marginal-likelihood-in-variational-autoencoders/" rel="next" title="Importance Sampling and Estimating Marginal Likelihood in Variational Autoencoders">Next post</a>
            </li>
        </ul></nav></aside><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha384-3lJUsx1TJHt7BA4udB5KPnDrlkO8T6J6v/op7ui0BbCjvZ9WqV4Xm6DTP6kQ/iBH" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'left', // Change this to 'center' to center equations.
    displayIndent: '2em',
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": "0em 0em 1em 0em"}}
    }
});
</script></article>
</div>
            <div class="col-md-3 ">
            <div class="card card-body bg-light">
            <p>
            Hi, I'm <a href="http://www.briankeng.com/about">Brian Keng</a>.  This is
            <a href="../../">the place</a> where I write about all things technical.
            </p>
            <p>
            Twitter: <a href="http://www.twitter.com/bjlkeng">@bjlkeng</a>
            </p>

            <br>
</div>

<!-- Begin MailChimp Signup Form -->
<hr>
<link href="//cdn-images.mailchimp.com/embedcode/classic-081711.css" rel="stylesheet" type="text/css">
<style type="text/css">
    #mc_embed_signup{clear:left; font:13px Helvetica,Arial,sans-serif; }
    /* Add your own MailChimp form style overrides in your site stylesheet or in this style block.
       We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
</style>
<div id="mc_embed_signup">
<form action="//briankeng.us10.list-manage.com/subscribe/post?u=cedf72ca8daa891e57f4379a0&amp;id=1f1563094f" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <b>Signup for Email Blog Posts</b>
    <div id="mc_embed_signup_scroll">
<div>
    <label for="mce-EMAIL"> Email Address </label>
    <input type="email" value="" name="EMAIL" class="required email form-control input-sm" id="mce-EMAIL">
</div>
    <div id="mce-responses" class="clear">
        <div class="response" id="mce-error-response" style="display:none"></div>
        <div class="response" id="mce-success-response" style="display:none"></div>
    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_cedf72ca8daa891e57f4379a0_1f1563094f" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="btn btn-default btn-xs"></div>
    </div>
</form>
</div>
<script type="text/javascript" src="//s3.amazonaws.com/downloads.mailchimp.com/js/mc-validate.js"></script><script type="text/javascript">(function($) {window.fnames = new Array(); window.ftypes = new Array();fnames[0]='EMAIL';ftypes[0]='email';fnames[1]='FNAME';ftypes[1]='text';fnames[2]='LNAME';ftypes[2]='text';}(jQuery));var $mcj = jQuery.noConflict(true);</script><!--End mc_embed_signup-->
</div>
            </div>
        </div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2024         <a href="mailto:brian@briankeng.com">Brian Keng</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
            
        </footer>
</div>



        <script src="../../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-15314898-2', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>
