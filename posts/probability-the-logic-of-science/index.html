<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Probability as extended logic.">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Probability as Extended Logic | Bounded Rationality</title>
<link href="../../assets/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/rst.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/code.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/colorbox.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/theme.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.xml">
<link rel="canonical" href="http://bjlkeng.github.io/posts/probability-the-logic-of-science/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="description" itemprop="description" content="Probability as extended logic.">
<meta name="author" content="Brian Keng">
<link rel="prev" href="../accessible-satisfiability/" title="Accessible Satisfiability" type="text/html">
<link rel="next" href="../gamblers-fallacy-and-the-law-of-small-numbers/" title="The Gambler's Fallacy and The Law of Small Numbers" type="text/html">
<meta property="og:site_name" content="Bounded Rationality">
<meta property="og:title" content="Probability as Extended Logic">
<meta property="og:url" content="http://bjlkeng.github.io/posts/probability-the-logic-of-science/">
<meta property="og:description" content="Probability as extended logic.">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2015-10-14T20:30:05-04:00">
<meta property="article:tag" content="Jayne">
<meta property="article:tag" content="logic">
<meta property="article:tag" content="mathjax">
<meta property="article:tag" content="probability">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="http://bjlkeng.github.io/">

                <span class="h1" id="blog-title">Bounded Rationality</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<p class="lead">Understanding math, machine learning, and data to a satisfactory degree.</p>
<!--
                
                <li><a href="/archive.html">Archive</a>
                <li><a href="/categories/">Tags</a>
                <li><a href="/rss.xml">RSS feed</a>

                 
-->
            </ul>
<ul class="nav navbar-nav navbar-right">
<li>
    <a href="index.rst" id="sourcelink">Source</a>
    </li>

                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            <div class="col-lg-9">
                
                
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Probability as Extended Logic</a></h1>

        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                    Brian Keng
            </span></p>
            <p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2015-10-14T20:30:05-04:00" itemprop="datePublished" title="2015-10-14 20:30">2015-10-14 20:30</time></a></p>
            
        <p class="sourceline"><a href="index.rst" class="sourcelink">Source</a></p>

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<p>Modern probability theory is typically derived from the
<a class="reference external" href="https://en.wikipedia.org/wiki/Probability_axioms">Kolmogorov axioms</a>,
using measure theory with concepts like events and sample space.
In one way, it's intuitive to understand how this works as Laplace
<a class="reference external" href="https://en.wikipedia.org/wiki/Classical_definition_of_probability">wrote</a>:</p>
<blockquote>
The probability of an event is the ratio of the number of cases favorable
to it, to the number of all cases possible, when [the cases are] equally
possible. ... Probability is thus simply a fraction whose numerator is the
number of favorable cases and whose denominator is the number of all the
cases possible.</blockquote>
<p>However, the intuition of this view of probability breaks down when we want to
do more complex reasoning.  After learning probability from the lens of coins,
dice and urns full of red and white balls, I still didn't feel that I had
have a strong grasp about how to apply it to other situations -- especially
ones where it was difficult or too abstract to apply the idea of <em>"a fraction
whose numerator is the number of favorable cases and whose denominator is the
number of all the cases possible"</em>.  And then I read <a class="reference external" href="http://www.cambridge.org/gb/academic/subjects/physics/theoretical-physics-and-mathematical-physics/probability-theory-logic-science">Probability Theory: The Logic of Science</a> by E. T. Jayne.</p>
<p>Jayne takes a drastically different approach to probability, not with events and
sample spaces, but rather as an extension of Boolean logic.  Taking this view made
a great deal of sense to me since I spent a lot of time <a class="reference external" href="../accessible-satisfiability">studying and reasoning</a> in Boolean logic.  The following post
is my attempt to explain Jayne's view of probability theory, where he derives
it from "common sense" extensions to Boolean logic.  (<em>Spoiler alert: he ends
up with pretty much the same mathematical system as Kolmogorov's probability
theory.</em>) I'll stay away from any heavy derivations and stick with the
intuition, which is exactly where I think this view of probability theory is most
useful.</p>
<!-- TEASER_END -->
<p><br></p>
<h4> Boolean Logic </h4>
<p><em>Note: Feel free to skip this section if you're already comfortable with Boolean logic.</em></p>
<p>Before we begin with probability, let's do a quick review of Boolean logic
(sometimes also called propositional logic or propositional calculus).
In the context of modeling real-world situations, we usually define
propositions to describe things we may want to reason about,
denoted by <span class="math">\(\{A, B, C \ldots\}\)</span>.  Propositions have an unambiguous
meaning, and must either true or false.  For example the following two
sentences could be propositions:</p>
<div class="math">
\begin{align*}
A &amp;:= \text{It is raining.} \\
B &amp;:= \text{It is cloudy.}
\end{align*}
</div>
<p>We could also define a logical relation between the two propositions
using an implication operator (colloquially if-then statement):</p>
<div class="math">
\begin{equation*}
\text{if }A\text{ is true, then }B\text{ is true} := \text{if it is raining, then it is cloudy}
\end{equation*}
</div>
<p></p>
<h5> Rules of Inference </h5>
<p>To reason about propositions, we usually use two forms of inference, <a class="reference external" href="https://en.wikipedia.org/wiki/Modus_ponens">modus ponens</a> (Rule R1), which uses a premise (the
"if-then" statement), and an antecedent (the "if" part), to derive the
consequent (the "then" part):</p>
<div class="math">
\begin{equation*}
\text{if }A\text{ is true, then }B\text{ is true}
\end{equation*}
</div>
<div class="math">
\begin{equation*}
\frac{A\text{ is true}}{\text{therefore, }B\text{ is true}}  \tag{R1}
\end{equation*}
</div>
<p>and similarly with <a class="reference external" href="https://en.wikipedia.org/wiki/Modus_tollens">modus tollens</a> (Rule R2),
which is the contrapositive and a logically equivalent statement:</p>
<div class="math">
\begin{equation*}
\text{if }A\text{ is true, then }B\text{ is true}
\end{equation*}
</div>
<div class="math">
\begin{equation*}
\frac{B\text{ is false}}{\text{therefore, }A\text{ is false}} \tag{R2}
\end{equation*}
</div>
<p>Both make intuitive sense when you try to apply it to examples above:</p>
<div class="math">
\begin{equation*}
\text{if it is raining, then it is cloudy}
\end{equation*}
</div>
<div class="math">
\begin{equation*}
\frac{\text{it is raining}}{\text{therefore, it is cloudy}}
\end{equation*}
</div>
<p>and:</p>
<div class="math">
\begin{equation*}
\text{if it is raining, then it is cloudy}
\end{equation*}
</div>
<div class="math">
\begin{equation*}
\frac{\text{it is not cloudy}}{\text{therefore, it is not raining}}
\end{equation*}
</div>
<p></p>
<h5> Basic Boolean Operators </h5>
<p>There are several basic Boolean operators which arise very naturally when
discussing propositions.  The most basic one is the <strong>negation</strong> (or "not")
operator, usually drawn with a bar above the proposition (or expression):</p>
<div class="math">
\begin{equation*}
\bar{A}
\end{equation*}
</div>
<p>The next one is <strong>conjunction</strong> (or the "and"
operator) meaning "both A and B are true", denoted by:</p>
<div class="math">
\begin{equation*}
AB
\end{equation*}
</div>
<p>The final one is <strong>disjunction</strong> (or the "or"
operator) meaning "at least one the propositions A, B are true", denoted with a "+" sign:</p>
<div class="math">
\begin{equation*}
A + B
\end{equation*}
</div>
<p>With the above examples, our intuition isn't too far off from the natural
English interpretation (except for "or", which is the inclusive one instead of
the exclusive one usually used in English):</p>
<div class="math">
\begin{align*}
\bar{A} &amp;:= \text{it is }\textbf{not}\text{ raining} \\
AB &amp;:= \text{it is raining }\textbf{and}\text{ it is cloudy} \\
A + B &amp;:= \text{it is raining }\textbf{or}\text{ it is cloudy (or both)}
\end{align*}
</div>
<p></p>
<h5> Limitations of Boolean Logic </h5>
<p>Boolean logic has wide applications in many areas.  It is one of the
fundamental ideas used in modern computing and one of the simplest symbolic
logic systems in modern use.  From one point of view, it's quite a natural
way to rationally reason about real-world problems.  With repeated
applications of Rules R1 or R2, we can logically "prove" a fact from a set of
premises.  In fact, this type of reasoning system has been used for centuries
with <a class="reference external" href="https://en.wikipedia.org/wiki/Term_logic">Aristotelian logic</a>.
However, it's not hard to see that it has some limitations on the kinds of
things that can be modeled with it.</p>
<p>For example, given our above proposition "it is raining", using Boolean logic,
we would have to assign this either a true or false value.
If we think a bit, we can probably come up with a situation where it's not so
clear whether the statement should be clearly true or false.
Perhaps I'm in my bedroom and my curtains are closed but I can see that it
looks kind of grey outside.  Am I 100% certain that it is raining, or is there
more like a 50/50 chance that it is raining?  Clearly, Boolean logic isn't quite
ready to handle these situations.  However, if we relaxed the criteria that
each proposition had to be 100% true or false and instead had a range values
corresponding to how "true" we think it is, we could come up with a reasoning
system that could be used to model a wider variety of real-world situations.
In the next section, we'll introduce some ideas to get us closer to this type
of system.</p>
<p><br></p>
<h4> Plausible Reasoning </h4>
<p>By relaxing the constraint of Boolean logic's strict true or false values, we
end up with a reasoning system that is more widely applicable.  For a
proposition such as "it is raining", no longer will we assign it just true or
false values, we instead want to assign it a value that represents to what
degree we believe it to be true.  We will call this degree of belief the
<em>plausibility</em> of a proposition.
Along with these extended truth values, we'd also like to develop rules so we
can reason about them while, ideally, still maintaining the same type of
deductive reasoning we have with Boolean logic.  Let's see how it works out.</p>
<p></p>
<h5> Weaker Rules of Inference </h5>
<p>We already saw two forms of inference from Boolean logic, Rule R1 and R2:</p>
<div class="math">
\begin{equation*}
\text{if }A\text{ is true, then }B\text{ is true}
\end{equation*}
</div>
<div class="math">
\begin{equation*}
\frac{A\text{ is true}}{\text{therefore, }B\text{ is true}}  \tag{R1}
\end{equation*}
</div>
<div class="math">
\begin{equation*}
\frac{B\text{ is false}}{\text{therefore, }A\text{ is false}} \tag{R2}
\end{equation*}
</div>
<p>These rules extend quite naturally to our degrees of plausibility.
For R1, if we think that A is plausible (to some degree), then
it intuitively makes sense that B becomes more plausible.
Similarly for R2, if we think B is implausible (to some degree), then
A should also become more implausible.
Using this line of reasoning, we can come up with some more rules of inference
that, while in Boolean logic would be non-sensical, do make sense in our
new system of reasoning with plausibilities.  Consider these new rules R3 and R4:</p>
<div class="math">
\begin{equation*}
\text{if }A\text{ is true, then }B\text{ is true}
\end{equation*}
</div>
<div class="math">
\begin{equation*}
\frac{B\text{ is true}}{\text{therefore, }A\text{ is more plausible}}  \tag{R3}
\end{equation*}
</div>
<div class="math">
\begin{equation*}
\frac{A\text{ is false}}{\text{therefore, }B\text{ is less plausible}} \tag{R4}
\end{equation*}
</div>
<p>If we try to apply it to our example above, it passes our simplest smoke test
of a rational line of reasoning:</p>
<div class="math">
\begin{equation*}
\text{if it is raining, then it is cloudy}
\end{equation*}
</div>
<div class="math">
\begin{equation*}
\frac{\text{it is cloudy}}{\text{therefore, it is more plausible that it is raining}}
\end{equation*}
</div>
<div class="math">
\begin{equation*}
\frac{\text{it is not raining}}{\text{therefore, it is less plausible that it is cloudy}}
\end{equation*}
</div>
<p>Here, if it's cloudy, we're not positive that it's raining but somehow it has increased
our belief that it will rain ("Is it going to rain?  It might, it looks cloudy.").
Alternatively, if it's not raining there is definitely some degree of plausibility
that it is not cloudy.  With Boolean logic and it's strict true/false
dichotomy, we cannot really make any conclusions from the premise but with
plausible reasoning we can change our degree of belief about the propositions.</p>
<p>Of course, there is not much precision (read: mathematics) in what we've said,
we're just trying to gain some intuition on how we would ideally reason about
propositions with varying degrees of plausibility.  In whatever system we end
up designing, we'd like to keep the spirit of R1-R4 in tact because it follows
what we would expect a smart rational person to conclude.</p>
<p></p>
<h5> Introducing the Robot </h5>
<p>In all of the above discussion about plausible reasoning, we've been trying to
build "a mathematical model of human common sense" as Jayne puts it.  However,
we need to be careful because human judgment has many properties (that while
useful) may not be ideal for us to include in our system of reasoning such as
emotion and misunderstandings.  Here is where Jayne introduces a really neat
concept, the robot, in order to make it clear what we're trying to achieve:</p>
<blockquote>
In order to direct attention to constructive things and away from
controversial irrelevancies, we shall invent an imaginary being.  Its brain
is to be designed <em>by us</em>, so that it reasons according to certain definite
rules.  These rules will be deduced from simple desiderata which, it
appears to us, would be desirable in human brains; i.e. we think that a
rational person, on discovering that they were violating one of these
desiderata, would wish to revise their thinking.
...
To each proposition about which it reasons, our robot must assign some
degree of plausibility, based on the evidence we have given it; and
whenever it receives new evidence it must revise these assignments to take
that new evidence into account.</blockquote>
<p>Sounds like a pretty cool robot!  So our goal now is to build a reasoning
system for this hypothetical robot that that will be consistent with how an
ideal rational person would reason.  Here are the three requirements
(desiderata) that Jayne states for our robot:</p>
<blockquote>
<ol class="arabic simple">
<li>Degrees of plausibility are represented by real numbers.</li>
<li>Qualitative correspondence with common sense.</li>
<li>Consistency:<ol class="loweralpha">
<li>If a conclusion can be reasoned out in more than one way, then every possible way must lead to the same result.</li>
<li>The robot always takes into account all of the evidence it has relevant to the question.  It does not arbitrarily, ignore some of the information, basing its conclusions only on what remains.  In other words, the robot is nonideological.</li>
<li>The robot always represents equivalent states of knowledge by equivalent plausibility assignments.  That is, if in two problems the robot's state of knowledge is the same (except perhaps for the labeling of the propositions), then it must assign the same plausibilities in both.</li>
</ol>
</li>
</ol>
</blockquote>
<p>The first requirement is mostly for practicality.  If we're building a machine,
we'd like some standard way to tell it about plausibility (and vice versa),
real numbers seem appropriate.
The second requirement tells us that the robot should at least qualitatively
reason like humans do.  For example, the robot should be able to reason
somewhat like our rules R1-R4 above, which is precisely the whole point of our
exercise.
The last requirement is obvious since if we're trying to build a robot
to reason, it has to be consistent (or what use is it?).</p>
<p>What is surprising is that from these three desiderata, Jayne goes on
to derive probability theory (extending it from Boolean logic)!  If you're
interested, I encourage you to check out his book Probability Theory: The Logic
of Science  (see link below), where in Chapter 2 he goes over all the gory
details.  It's quite an interesting read and pretty accessible if you know a
bit of calculus and are comfortable with some algebraic manipulation.  I'll
spare you the details here on how the derivation plays out (as I'm probably not
the right person to explain it) but instead I want to focus on how probability
theory can be viewed as an extension of Boolean logic.</p>
<p><br></p>
<h4> Probability as Extended Logic </h4>
<p>The rules of probability have direct analogues with our Boolean operators above
(as it can be viewed as an extension of them).
Now our propositions don't have 0 or 1 truth values, they can take on any value
in the range 0 (false) to 1 (true) representing their plausibility.  The symbol
<span class="math">\(P(A|B)\)</span> is used to denote the degree of plausibility we assign
proposition A, given our background or prior knowledge B (remember the robot
will take all relevant known information into account).</p>
<p>The really interesting insight is that all the concepts from Boolean logic are
just limiting cases of our extension (i.e. probability theory) where our robot
becomes more and more certain of itself.  Let's take a look.</p>
<p></p>
<h5> Extended Boolean Operators </h5>
<p>Consider negation ("not" operator).  The analogue in probability theory is the
basic sum rule:</p>
<div class="math">
\begin{equation*}
P(A|B) + P(\bar{A}|B) = 1
\end{equation*}
</div>
<p>If we are entirely confident in proposition A (i.e. <span class="math">\(P(A|B)=1\)</span> or A is true),
then from the above rule, we can conclude <span class="math">\(P(\bar{A}|B) = 1 - P(A|B) = 0\)</span>,
or <span class="math">\(\bar{A}\)</span> is false.</p>
<p>This works equally well with our two basic Boolean operators.  Consider the "and"
operator, it's analogue is the basic form of the product rule:</p>
<div class="math">
\begin{equation*}
P(AB|C) = P(A|BC)P(B|C) = P(B|AC)P(A|C)
\end{equation*}
</div>
<p>Let's try a few cases out.  If A is true and B is true, we should see that AB
is true.  Translating that to probabilities, we get <span class="math">\(P(A|C)=1\)</span> and
<span class="math">\(P(B|C)=1\)</span>.  Now this doesn't fit as nicely into our product rule
but we just need to go back to the concept of our robot taking all known
information into account.</p>
<p>Consider the second form of the product rule: <span class="math">\(P(AB|C) = P(B|AC)P(A|C)\)</span>.
We know that <span class="math">\(P(B|C)=1\)</span>, this means that given background information
<span class="math">\(C\)</span>, we know enough to conclude that <span class="math">\(B\)</span> is plausible with absolute
certainty.
When we add the additional information that A is plausible with absolute
certainty (i.e. <span class="math">\(B|AC\)</span>), it doesn't have any affect on <span class="math">\(B\)</span> (because
C is already telling us that <span class="math">\(B\)</span> is true) <a class="footnote-reference" href="#id2" id="id1">[1]</a>.
From this, we can conclude that <span class="math">\(P(B|AC)=1\)</span> because the fact <span class="math">\(A\)</span>
is irrelevant to our robot when computing <span class="math">\(P(B|AC)\)</span>.</p>
<p>Plugging that along with <span class="math">\(P(A|C)=1\)</span> into the formula we get the desired
result of <span class="math">\(P(AB|C)=1\)</span>.  And since the "and" operator is commutative, we could
have easily used the first form and reached the same conclusion.
Alternatively, if we try <span class="math">\(P(A|C)=1\)</span> and <span class="math">\(P(B|C)=0\)</span>, we can see
through a similar line of reasoning that the result should be
<span class="math">\(P(AB|C)=0\)</span>.</p>
<p>The last basic Boolean operator "or" also has a direct analogue in the extended sum
rule:</p>
<div class="math">
\begin{equation*}
P(A + B|C) = P(A|C) + P(B|C) - P(AB|C)
\end{equation*}
</div>
<p>Taking a similar line of reasoning, if we have <span class="math">\(P(A|C)=0\)</span> and
<span class="math">\(P(B|C)=1\)</span>, we have <span class="math">\(P(AB|C)=0\)</span> from the above line of reasoning.
With these three quantities, we can easily compute <span class="math">\(P(A + B|C)=1\)</span>, as we
would expect (If A is false and B is true, then "A or B" is true).  The other
combinations of truth values for <span class="math">\(A\)</span> and <span class="math">\(B\)</span> yield a similar result.</p>
<p></p>
<h5> Extended Reasoning </h5>
<p>As we saw before, we would ideally like our original rules (R1 and R2) as well
as our extended rules (R1-R4) to be included in our new system.
As expected, these common sense interpretations are preserved in probability
theory with a modified form of the product rule.</p>
<p>Recall the rules R1 and R2:</p>
<div class="math">
\begin{equation*}
\text{if }A\text{ is true, then }B\text{ is true}
\end{equation*}
</div>
<div class="math">
\begin{equation*}
\frac{A\text{ is true}}{\text{therefore, }B\text{ is true}}  \tag{R1}
\end{equation*}
</div>
<div class="math">
\begin{equation*}
\frac{B\text{ is false}}{\text{therefore, }A\text{ is false}} \tag{R2}
\end{equation*}
</div>
<p>The premise can be encoded in our background information <span class="math">\(C\)</span>:</p>
<div class="math">
\begin{equation*}
C \equiv A \implies B
\end{equation*}
</div>
<p>Given this background information, we can use these forms of the product rule to encode
R1, R2 as rules PR1 and PR2, respectively:</p>
<div class="math">
\begin{align*}
P(B|AC) = \frac{P(AB|C)}{P(A|C)}                    \tag{PR1} \\
P(A|\bar{B}C) = \frac{P(A\bar{B}|C)}{P(\bar{B}|C)}  \tag{PR2}
\end{align*}
</div>
<p>This is not all that obvious because we lose some of the nice one-to-one
correspondence like the operators above.  However, treating A, B, C as
propositions aids us in understanding these equations.  Given our major premise
<span class="math">\(C \equiv A \implies B\)</span>, let's look at the truth table for the relevant
propositions.</p>
<table border="1" class="docutils">
<colgroup>
<col width="7%">
<col width="7%">
<col width="41%">
<col width="20%">
<col width="25%">
</colgroup>
<thead valign="bottom"><tr>
<th class="head">A</th>
<th class="head">B</th>
<th class="head"><span class="math">\(C \equiv A \implies B\)</span></th>
<th class="head"><span class="math">\(AB | C\)</span></th>
<th class="head"><span class="math">\(A\bar{B}|C\)</span></th>
</tr></thead>
<tbody valign="top">
<tr>
<td>False</td>
<td>False</td>
<td>True</td>
<td>False</td>
<td>False</td>
</tr>
<tr>
<td>False</td>
<td>True</td>
<td>True</td>
<td>False</td>
<td>False</td>
</tr>
<tr>
<td>True</td>
<td>False</td>
<td>False</td>
<td><em>Impossible</em></td>
<td><em>Impossible</em></td>
</tr>
<tr>
<td>True</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td>False</td>
</tr>
</tbody>
</table>
<p>Notice that this truth table is a bit special in that I am mixing our extended logic
with Boolean logic (e.g. <span class="math">\(|\)</span> symbol).  Although it's not really proper to
do so, this is more an exercise in intuition than anything else so I'll stick
with the sloppiness for sake of explanation.
Next, we see that I have filled in a special notation for the third row
using the term "<em>impossible</em>".  This is to indicate, given the premise <span class="math">\(C\)</span>,
this situation cannot possibly occur (or else our premise would be false).</p>
<p>Now given this truth table, we can see that <span class="math">\(AB | C\)</span> simplifies to
the expression <span class="math">\(A|C\)</span> by ignoring the impossible row from our premise (the
first, second and fourth rows match).
Similarly, <span class="math">\(A\bar{B}|C\)</span> simplifies to "False" (by ignoring the third
row).  Plugging these back into PR1 and PR2:</p>
<div class="math">
\begin{align*}
P(B|AC) = \frac{P(AB|C)}{P(A|C)} = \frac{P(A|C)}{P(A|C)} = 1  \\
P(A|\bar{B}C) = \frac{P(A\bar{B}|C)}{P(\bar{B}|C)} = \frac{0}{P(\bar{B}|C)} = 0
\end{align*}
</div>
<p>we get the desired result.  In particular, <span class="math">\(P(B|AC)\)</span> tells us the same
thing that <span class="math">\(A \implies B\)</span> combined with <span class="math">\(A\text{ is True}\)</span> tells us:
<span class="math">\(B\)</span> is true.  Similarly, <span class="math">\(P(A|\bar{B}C)\)</span> resolves to the same thing
that <span class="math">\(A \implies B\)</span> combined with <span class="math">\(\bar{B}\)</span> resolves to:
<span class="math">\(A\)</span> is false.  Pretty neat, huh?</p>
<p>The rules R3 and R4 also extend quite naturally from our product rule.  Recall
rules R3 and R4:</p>
<div class="math">
\begin{equation*}
\text{if }A\text{ is true, then }B\text{ is true}
\end{equation*}
</div>
<div class="math">
\begin{equation*}
\frac{B\text{ is true}}{\text{therefore, }A\text{ is more plausible}}  \tag{R3}
\end{equation*}
</div>
<div class="math">
\begin{equation*}
\frac{A\text{ is false}}{\text{therefore, }B\text{ is less plausible}} \tag{R4}
\end{equation*}
</div>
<p>R3 can be encoded as this form of the product rule:</p>
<div class="math">
\begin{equation*}
P(A|BC) = P(A|C)\frac{P(B|AC)}{P(B|C)}
\end{equation*}
</div>
<p>But from the discussion above, we know <span class="math">\(P(B|AC)=1\)</span> and
<span class="math">\(P(B|C) \leq 1\)</span> (from the definition of a probability), so it must be the
case that:</p>
<div class="math">
\begin{equation*}
P(A|BC) \geq P(A|C)  \tag{E1}
\end{equation*}
</div>
<p>In other words, given new information <span class="math">\(B\)</span>, we now think <span class="math">\(A\)</span> is more
plausible. We can build upon this reasoning to understand R4 using this form of
the product rule:</p>
<div class="math">
\begin{equation*}
P(B|\bar{A}C) = P(B|C)\frac{P(\bar{A}|BC)}{P(\bar{A}|C)}
\end{equation*}
</div>
<p>From E1, we know that <span class="math">\(P(\bar{A}|BC) \leq P(\bar{A}|C)\)</span> (remember
the "not" rule), so we can conclude that:</p>
<div class="math">
\begin{equation*}
P(B|\bar{A}C) \leq P(B|C)
\end{equation*}
</div>
<p>which says that given <span class="math">\(\bar{A}\)</span>, proposition <span class="math">\(B\)</span> becomes less
plausible.</p>
<p><br></p>
<h4> Conclusion </h4>
<p>Probability as an extension of logic is quite a different approach compared to
the traditional treatment of the subject.  I've tried to shed some light on
this view of probability and hopefully have provided some intuition on how it
all works.
For me, probability as an extension of logic is much more natural way of
looking at the subject while also much more philosophically satisfying.  It also
directly leads to a Bayesian interpretation of data (because you're just
updating our robot's prior knowledge), which also makes a lot of sense to me.  It's a
shame that probability isn't taught (or even mentioned) in the context of
extended logic because I think it would help people internalize the concepts a
lot better and, dare I say, even start to like the subject!</p>
<p><br></p>
<h4> Further Reading </h4>
<ul class="simple">
<li>
<a class="reference external" href="http://bayes.wustl.edu/etj/prob/book.pdf">Probability Theory: The Logic of Science (Chapters 1-3)</a> by E. T. Jayne.</li>
<li>
<a class="reference external" href="http://bayes.wustl.edu/">Probability Theory As Extended Logic</a> at Washington University In St Louis.</li>
<li>
<a class="reference external" href="http://nbviewer.ipython.org/url/norvig.com/ipython/Probability.ipynb">Probability, Paradox, and the Reasonable Person Principle</a> by Peter Norvig</li>
</ul>
<p><br></p>
<table class="docutils footnote" frame="void" id="id2" rules="none">
<colgroup>
<col class="label">
<col>
</colgroup>
<tbody valign="top"><tr>
<td class="label"><a class="fn-backref" href="#id1">[1]</a></td>
<td>You might wonder what happens when <span class="math">\(A\)</span> and <span class="math">\(C\)</span> are mutually exclusive propositions (i.e. impossible to happen at the same time).  In this case, <span class="math">\(P(B|AC)\)</span> is not defined but also our original question is ill formed because we couldn't have the case <span class="math">\(P(A|C)=1\)</span> (we would instead have <span class="math">\(P(A|C)=1\)</span>).</td>
</tr></tbody>
</table>
</div>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/jayne/" rel="tag">Jayne</a></li>
            <li><a class="tag p-category" href="../../categories/logic/" rel="tag">logic</a></li>
            <li><a class="tag p-category" href="../../categories/probability/" rel="tag">probability</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../accessible-satisfiability/" rel="prev" title="Accessible Satisfiability">Previous post</a>
            </li>
            <li class="next">
                <a href="../gamblers-fallacy-and-the-law-of-small-numbers/" rel="next" title="The Gambler's Fallacy and The Law of Small Numbers">Next post</a>
            </li>
        </ul></nav></aside><script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script><script type="text/x-mathjax-config">
                    MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']]}});
                    </script></article>
</div>
            <div class="col-md-3 well">
            <p>
            I'm <a href="http://www.briankeng.com/about">Brian Keng</a>, 
            a former academic, current data scientist and engineer.  This is
            <a href="../../">the place</a>
            where I write
            about all things technical.
            </p>
            <p>
            Twitter: <a href="http://www.twitter.com/bjlkeng">@bjlkeng</a>
            </p>

            <br><p>
            <a href="../../archive.html">Archive</a>
            </p>
            <p>
            <a href="../../categories/index.html">Tags</a>
            </p>
            <p>
            <a href="../../rss.xml">RSS feed</a>
            </p>

<!-- Begin MailChimp Signup Form -->
<hr>
<link href="//cdn-images.mailchimp.com/embedcode/classic-081711.css" rel="stylesheet" type="text/css">
<style type="text/css">
    #mc_embed_signup{clear:left; font:13px Helvetica,Arial,sans-serif; }
    /* Add your own MailChimp form style overrides in your site stylesheet or in this style block.
       We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
</style>
<div id="mc_embed_signup">
<form action="//briankeng.us10.list-manage.com/subscribe/post?u=cedf72ca8daa891e57f4379a0&amp;id=1f1563094f" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <b>Signup for Email Blog Posts</b>
    <div id="mc_embed_signup_scroll">
<div>
    <label for="mce-EMAIL"> Email Address </label>
    <input type="email" value="" name="EMAIL" class="required email form-control input-sm" id="mce-EMAIL">
</div>
    <div id="mce-responses" class="clear">
        <div class="response" id="mce-error-response" style="display:none"></div>
        <div class="response" id="mce-success-response" style="display:none"></div>
    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_cedf72ca8daa891e57f4379a0_1f1563094f" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="btn btn-default btn-xs"></div>
    </div>
</form>
</div>
<script type="text/javascript" src="//s3.amazonaws.com/downloads.mailchimp.com/js/mc-validate.js"></script><script type="text/javascript">(function($) {window.fnames = new Array(); window.ftypes = new Array();fnames[0]='EMAIL';ftypes[0]='email';fnames[1]='FNAME';ftypes[1]='text';fnames[2]='LNAME';ftypes[2]='text';}(jQuery));var $mcj = jQuery.noConflict(true);</script><!--End mc_embed_signup-->
</div>
        </div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2019         <a href="mailto:brian@briankeng.com">Brian Keng</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
        </footer>
</div>
</div>


            <script src="../../assets/js/jquery.min.js"></script><script src="../../assets/js/bootstrap.min.js"></script><script src="../../assets/js/moment-with-locales.min.js"></script><script src="../../assets/js/fancydates.js"></script><script src="../../assets/js/jquery.colorbox-min.js"></script><!-- <script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script> --><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-15314898-2', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>
